{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 머신러닝 모델 이해 전략\n",
    "-> 먼저 기본이 되는 모델을 학습하고 -> 동시에 추가로, 이론을 깊게 학습하는 것이 좋다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 조건부 확률, 결합확률, 주변확률\n",
    "\n",
    "1. 조건부 확률\n",
    "- 어떤 사건이 일어났다는 조건 하에 다른 사건이 일어날 확률\n",
    "- **P(나타날 조건 | 먼저 정해진 조건)**\n",
    "\n",
    "2. 결합 확률\n",
    "- 두 사건이 동시에 일어날 확률\n",
    "- **P(조건1, 조건2)**\n",
    "\n",
    "3. 주변 확률\n",
    "- 두 사건이 동시에 일어날 수 있을 때, **하나의 특정 사건에 주목**하여 그것이 일어날 확률\n",
    "- **P(조건 1 + 조건 2)**\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 독립(independent)\n",
    "\n",
    "- X, Y 두 랜덤 변수가 서로 영향을 미치지 못하면 **독립** 이라고 한다.\n",
    "- 두 랜덤 변수가 독립이려면, **P(X, Y) = P(X) * P(Y)**\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 사전 확률(prior probability)\n",
    "- P(X)는 사전 확률\n",
    "- X(원인)이 발생할 확률과 같이 **결과가 나타나기 전에 결정되어 있는 확률**\n",
    "\n",
    "### 사후 확률\n",
    "- B(결과,예측값)가 발생하였다는 조건 하에 이 결과가 A(원인)로 인해 발생하였을 확률\n",
    "- P(A|**B**)\n",
    "\n",
    "\n",
    "### 우도(가능도, likelihood)\n",
    "- 'A(원인)'이 발생하였다는 조건 하에, B(결과)가 발생할 확률\n",
    "- P(B|**A**)\n",
    "- 조건부 확률로 계산이 가능"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 사전 확률, 우도, 사후 확률 예시\n",
    "\n",
    "딸기맛 사탕이 뽑혔는데, 어느 상자에서 나왔는가?\n",
    "- 전략1 (사전 확률)\n",
    "    - 상자 A와 B의 선택 가능성을 비교해서 큰 쪽을 취하자\n",
    "    - P(A) = 6 / 10 > P(B) = 4 / 10 이므로 '상자 A에서 나왔다' 라고 말한다.\n",
    "=> 이것을 **사전 확률** P(x)를 사용해서 비교했다고 말한다.\n",
    "\n",
    "\n",
    "- 전략2 (우도)\n",
    "    - 상자 A와 B(원인)를 선택한 후, 각 상자에서 딸기맛 사탕이 뽑힐 확률(결과)을 비교해서 큰 쪽을 취하자.\n",
    "    - P(딸기맛 | B) = 6 / 10 > P(딸기맛 | A ) = 2/ 10 이므로 '상자 B에서 나왔다'라고 말한다.\n",
    "\n",
    "\n",
    "=> 따라서, 사전확률과 우도를 사용하면 어느 것이 정확한지 알 수 없다.\n",
    "=> 따라서, **'딸기맛 사탕'이 관찰된 조건 하에** P(A|딸기맛), P(B|딸기맛) 을 비교하여 큰 쪽을 취하는 것이 합리적이다.\n",
    "=> 즉, P(X[원인] | Y[결과]) - **사후확률**을 사용하는 것이 보다 정확할 수 있다.\n",
    "    - **그러나, 사후 확률은 직접 계산할 수 없다.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 베이즈 정리\n",
    "- **사후 확률**은 **사전 확률**과 **우도**를 사용해서 계산할 수 있다.\n",
    "- 이를 **베이즈 정리** 라고 한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 베이즈 정리 활용\n",
    "\n",
    "- 문제: 메일에 쿠폰이라는 단어가 들어있는 메일이 스팸일 확률은?\n",
    "- 베이즈 정리로 생각해보기\n",
    "    - 원인: spam, 결과: 메일에 쿠폰이 들어있음.\n",
    "    - **P(원인 | 결과) = P (결과 | 원인) x P (원인) / P(결과)**\n",
    "    - **사후확률 = 사전확률 x 우도 / 주변확률**\n",
    "\n",
    "- P(spam | coupon)\n",
    "- P(promotion | coupon)\n",
    "- P(smap | coupon)\n",
    "\n",
    "- 전 세계의 모든 메일과 프로모션, 스팸 타입을 알 수 없으니\n",
    "- **샘플(훈련)데이터**를 통해 추정하는 것이 현실적이다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 베이즈 정리를 활용한 분류(Classfication) 프로세스 정리\n",
    "1. 샘플 수집: 수집된 **메일** 데이터 (전체 데이터가 아닌 샘플 데이터임)\n",
    "2. 샘플을 두 집합으로 분리\n",
    "    - 훈련 집합(training set): **스팸인지 아닌지를 미리 분석한 샘플들**\n",
    "    - 테스트 집합(test set): **스팸인지 아닌지 분류 결과가 없는 샘플들**\n",
    "3. 분류기 설계: 베이시언 분류기로 모델 구성\n",
    "4. 분류한 모델에 맞도록 샘플에서 특징(feature) 추출/가공\n",
    "    - 샘플에서, 쿠폰 단어가 들어있는지, 스팸인지를 나타내는 정보 추출/가공\n",
    "5. 훈련 집합을 분류기에 넣어, 학습\n",
    "    - P(coupon), P(spam), P(coupon | spam) 계산\n",
    "6. 테스트 집합으로 분류 예측 후, 성능 평가\n",
    "    - **사후확률**로 분류 후, 실제 스팸인지를 비교해서, 성능 평가"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 필기체 인식을 위한 베이시언 분류기 프로세스 정리\n",
    "- 부류(class): 0(w0) ~ 9(w9) 까지 숫자\n",
    "- 필기 데이터에서 추출한 feature: 벡터 x (수학으로만 생각)\n",
    "- 필기 글씨 x (결과)가, 숫자 1을 의도해서 작성된 w1(원인)에서 나올 사후확률\n",
    "    - **P(w[원인] | x[결과])**\n",
    "- 베이지언 분류기: 주어진 특징 벡터 x에 대해 '가장 그럴듯한 부류'로 분류\n",
    "    - P(wo | x ) ~ P(w9 | x) 중 가장 높은 확률 가진 부류로 분류"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 사전확률과 우도를 정확히 계산하기 어렵다는 문제점\n",
    "- 사전확률 P(wi)와 우도 P(x|wi)를 통해, 사후확률 P(wi | x)을 계산해야 함.\n",
    "- 따라서, 샘플 데이터 기반 분포 추정 수학적 기법을 동원하여 추정한다.\n",
    "\n",
    "### 나이브 베이즈 분류(Naive Bayes Classfication)\n",
    "- 현실 세계의 문제는 보다 복잡하다. ->  조건이 늘어나면 계산 조건이 증폭됨.\n",
    "- P(coupon | spam) + P(stock | spam) - P(coupon ^ stock| spam)\n",
    "- 이를 차원의 저주라고 한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GaussianNB(Gaussian Naive Bayes)\n",
    "1. 샘플 수집: 수집된 **메일** 데이터 (전체 데이터가 아닌 샘플 데이터임)\n",
    "2. 샘플을 두 집합으로 분리\n",
    "    - 훈련 집합(training set): **스팸인지 아닌지를 미리 분석한 샘플들**\n",
    "    - 테스트 집합(test set): **스팸인지 아닌지 분류 결과가 없는 샘플들**\n",
    "3. 분류기 설계: 나이브 베이즈 분류기로 모델 구성\n",
    "4. 분류한 모델에 맞도록 샘플에서 특징(feature) 추출/가공\n",
    "    - 샘플에서, 쿠폰 단어가 들어있는지, 스팸인지를 나타내는 정보 추출/가공\n",
    "5. 훈련 집합을 분류기에 넣어, 학습\n",
    "    - P(coupon), P(spam), P(coupon | spam) 각각을 **샘플 데이터 기반 정규분포**(가우스 분포)를 통해 전체 데이터를 추정\n",
    "6. 테스트 집합으로 분류 예측 후, 성능 평가\n",
    "    - **사후확률**로 분류 후, 실제 스팸인지를 비교해서, 성능 평가"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
