{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 중요도에 따른 feature 정리\n",
    "- 분류 확률을 계산하는데 기여한 정도를 **피처 중요도** 라고 한다.\n",
    "- 결과에 유의미한 영향을 주는 feature만을 중심으로 머신러닝 기법을 적용하기도 한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Pclass_0  Pclass_1  Pclass_2  Sex_0  Sex_1  Age_0  Age_1  Age_2  Age_3  \\\n0         0         0         1      1      0      0      0      0      1   \n1         1         0         0      0      1      0      0      0      0   \n2         0         0         1      0      1      0      0      0      1   \n3         1         0         0      0      1      0      0      0      0   \n4         0         0         1      1      0      0      0      0      0   \n\n   Age_4  ...  HighChance_0  HighChance_1  HighChance_2  HighChance_3  \\\n0      0  ...             1             0             0             0   \n1      1  ...             0             0             1             0   \n2      0  ...             1             0             0             0   \n3      1  ...             0             0             1             0   \n4      1  ...             1             0             0             0   \n\n   HighChance_4  HighChance_5  HighChance_6  LowChance_0  LowChance_1  \\\n0             0             0             0            1            0   \n1             0             0             0            1            0   \n2             0             0             0            1            0   \n3             0             0             0            1            0   \n4             0             0             0            0            0   \n\n   LowChance_2  \n0            0  \n1            0  \n2            0  \n3            0  \n4            1  \n\n[5 rows x 94 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass_0</th>\n      <th>Pclass_1</th>\n      <th>Pclass_2</th>\n      <th>Sex_0</th>\n      <th>Sex_1</th>\n      <th>Age_0</th>\n      <th>Age_1</th>\n      <th>Age_2</th>\n      <th>Age_3</th>\n      <th>Age_4</th>\n      <th>...</th>\n      <th>HighChance_0</th>\n      <th>HighChance_1</th>\n      <th>HighChance_2</th>\n      <th>HighChance_3</th>\n      <th>HighChance_4</th>\n      <th>HighChance_5</th>\n      <th>HighChance_6</th>\n      <th>LowChance_0</th>\n      <th>LowChance_1</th>\n      <th>LowChance_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 94 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "with open('titanic_step3_feature_onehot_encoding.pickle', 'rb') as pickle_filename:\n",
    "    df_onehot = pickle.load(pickle_filename)\n",
    "with open('titanic_step3_feature_encoding_y_pickle', 'rb') as pickle_filename:\n",
    "    y_train = pickle.load(pickle_filename)\n",
    "ntrain = 891\n",
    "X_train, X_test = df_onehot[:ntrain], df_onehot[ntrain:]\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np # 각 모델에서 내부적으로 관련 라이브러리 사용 가능\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier             # 1. K-Nearest Neighbor(KNN)\n",
    "from sklearn.linear_model import LogisticRegression            # 2. Logistic Regression\n",
    "from sklearn.svm import SVC                                                # 3. SVC\n",
    "from sklearn.tree import DecisionTreeClassifier                   # 4. Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier       # 5. Random Forest\n",
    "from sklearn.ensemble import ExtraTreesClassifier             # 6. Extra Tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier  # 7. GBM\n",
    "from sklearn.naive_bayes import GaussianNB                     # 8. GaussianNB\n",
    "from xgboost import XGBClassifier                                     # 9. XGBoost\n",
    "from lightgbm import LGBMClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### default test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "logreg_model = LogisticRegression()\n",
    "svc_model = SVC()\n",
    "decision_model = DecisionTreeClassifier()\n",
    "random_model = RandomForestClassifier()\n",
    "extra_model = ExtraTreesClassifier()\n",
    "gbm_model = GradientBoostingClassifier()\n",
    "nb_model = GaussianNB()\n",
    "xgb_model = XGBClassifier(eval_metric='logloss')\n",
    "lgbm_model = LGBMClassifier()\n",
    "\n",
    "models = [\n",
    "    knn_model,\n",
    "    logreg_model,\n",
    "    svc_model,\n",
    "    decision_model,\n",
    "    random_model,\n",
    "    extra_model,\n",
    "    gbm_model,\n",
    "    nb_model,\n",
    "    xgb_model,\n",
    "    lgbm_model\n",
    "]\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)           # K-Fold 사용\n",
    "results = dict()\n",
    "for alg in models:\n",
    "    alg.fit(X_train, y_train)\n",
    "    score = cross_val_score(alg, X_train, y_train.values.ravel(), cv=k_fold, scoring='accuracy')\n",
    "    results[alg.__class__.__name__] = np.mean(score)*100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'KNeighborsClassifier': 83.27715355805243,\n 'LogisticRegression': 83.50187265917603,\n 'SVC': 83.05118601747814,\n 'DecisionTreeClassifier': 80.1323345817728,\n 'RandomForestClassifier': 82.03870162297129,\n 'ExtraTreesClassifier': 81.92634207240947,\n 'GradientBoostingClassifier': 82.48938826466915,\n 'GaussianNB': 71.81647940074906,\n 'XGBClassifier': 81.4769038701623,\n 'LGBMClassifier': 82.14981273408239}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 정확도 높은 순으로 정렬하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[('LogisticRegression', 83.50187265917603),\n ('KNeighborsClassifier', 83.27715355805243),\n ('SVC', 83.05118601747814),\n ('GradientBoostingClassifier', 82.48938826466915),\n ('LGBMClassifier', 82.14981273408239),\n ('RandomForestClassifier', 82.03870162297129),\n ('ExtraTreesClassifier', 81.92634207240947),\n ('XGBClassifier', 81.4769038701623),\n ('DecisionTreeClassifier', 80.1323345817728),\n ('GaussianNB', 71.81647940074906)]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(results.items(), key=lambda  x:x[1], reverse=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 성능이 좋은 머신러닝 기법만으로 중요도 계산하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "tree_models = [\n",
    "    random_model,\n",
    "    extra_model,\n",
    "    gbm_model,\n",
    "    xgb_model\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 트리 관련 모델은 중요도가 측정됨\n",
    "- 트리를 결정하는 과정에서 각 feature 가 얼마나 중요한지를 수치화하며, feature_importances_ 에 해당 값을 가지고 있음\n",
    "- 해당 값을 기준으로 중요도가 낮은 feature 를 걸러낼 수 있음"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "[1.47146345e-02 1.50214399e-02 3.58106121e-02 7.00953557e-02\n",
      " 5.64699737e-02 4.65514321e-03 8.42237687e-03 1.29722822e-02\n",
      " 2.03238846e-02 1.86534969e-02 1.58370585e-02 5.12774626e-03\n",
      " 1.27993158e-03 0.00000000e+00 2.36012643e-02 1.65002056e-02\n",
      " 9.38635601e-03 5.10694062e-03 4.38488246e-03 6.61711460e-03\n",
      " 3.03510574e-03 7.57610904e-03 7.63437201e-03 8.20487258e-03\n",
      " 9.31207005e-03 1.52031703e-03 1.43971286e-03 5.45697904e-04\n",
      " 3.32015990e-02 1.84108129e-02 1.42373101e-02 1.02235152e-02\n",
      " 9.59349654e-02 2.45839717e-02 2.28398113e-02 1.09572743e-02\n",
      " 4.41863450e-05 1.79556536e-04 2.22005265e-03 1.98632636e-03\n",
      " 9.01514567e-04 3.07596282e-04 5.77366901e-04 4.51189365e-04\n",
      " 1.60021783e-04 7.66641513e-04 1.63614431e-02 1.35321362e-02\n",
      " 1.57952879e-02 6.77341739e-03 6.88222252e-03 9.01053067e-03\n",
      " 2.73260634e-03 2.35483498e-03 1.47397957e-03 5.05122774e-03\n",
      " 5.87942445e-03 5.35338412e-03 1.24390019e-02 7.90198921e-04\n",
      " 3.08782642e-03 1.53047206e-03 3.89108545e-04 4.62216626e-03\n",
      " 2.92504019e-03 3.64847968e-04 2.76381605e-03 8.10472469e-05\n",
      " 2.02225676e-03 1.48928543e-03 4.47526284e-03 2.51312436e-05\n",
      " 0.00000000e+00 0.00000000e+00 1.42649203e-02 1.62604496e-02\n",
      " 1.97296246e-02 7.78548543e-03 1.03744138e-02 1.18687181e-02\n",
      " 8.64982441e-03 1.49298059e-02 1.65231966e-02 1.17746048e-02\n",
      " 3.20667547e-02 4.12536648e-03 5.70976541e-03 1.03278905e-02\n",
      " 5.23951953e-04 2.68536660e-05 8.62536739e-04 3.54988728e-02\n",
      " 1.30139862e-02 1.52443522e-02]\n",
      "ExtraTreesClassifier\n",
      "[1.85554867e-02 1.78806516e-02 3.54703128e-02 6.09692015e-02\n",
      " 8.58700911e-02 4.99047017e-03 1.03606815e-02 1.37523603e-02\n",
      " 2.09047749e-02 1.72983114e-02 1.59267246e-02 6.14959564e-03\n",
      " 1.58016324e-03 0.00000000e+00 1.99602166e-02 1.51471882e-02\n",
      " 9.70805313e-03 4.86602440e-03 3.25061469e-03 6.73885077e-03\n",
      " 2.65496907e-03 7.04354887e-03 7.11889808e-03 9.33637749e-03\n",
      " 1.01544027e-02 1.19013617e-03 1.63792302e-03 4.20585265e-04\n",
      " 2.34591130e-02 1.69323776e-02 1.14687132e-02 9.11095680e-03\n",
      " 8.98069663e-02 2.78581625e-02 2.12814113e-02 9.00067186e-03\n",
      " 0.00000000e+00 2.10803828e-04 1.59016944e-03 1.38283242e-03\n",
      " 1.15741161e-03 5.39349179e-04 5.40102578e-04 2.99006728e-04\n",
      " 1.89644302e-04 8.73130454e-04 1.24394375e-02 1.30334046e-02\n",
      " 1.63844002e-02 8.02212842e-03 6.88394230e-03 7.62517184e-03\n",
      " 2.18850567e-03 2.35695331e-03 2.25112377e-03 5.09393663e-03\n",
      " 4.54989578e-03 4.76408438e-03 1.47327459e-02 1.30574570e-03\n",
      " 2.95878963e-03 6.97243788e-04 3.72611934e-04 4.27375796e-03\n",
      " 3.26073956e-03 3.98201729e-04 2.93453866e-03 9.63087091e-05\n",
      " 1.87690078e-03 1.84836980e-03 5.49184234e-03 2.22401122e-05\n",
      " 0.00000000e+00 0.00000000e+00 1.28493432e-02 1.49482578e-02\n",
      " 2.00593935e-02 7.82206466e-03 1.05798151e-02 1.24482155e-02\n",
      " 8.30540074e-03 1.24293052e-02 1.46896294e-02 1.24827579e-02\n",
      " 4.05863194e-02 5.32008563e-03 7.65307137e-03 1.00331539e-02\n",
      " 8.06619277e-04 2.79541583e-05 5.79974512e-04 4.25641240e-02\n",
      " 6.69575240e-03 8.61830458e-03]\n",
      "GradientBoostingClassifier\n",
      "[1.44084892e-02 0.00000000e+00 1.14702845e-01 2.87554623e-02\n",
      " 8.41642690e-02 4.32913046e-04 1.07708954e-03 1.14408384e-03\n",
      " 3.74453954e-03 8.43513123e-03 8.22755359e-03 9.37802897e-03\n",
      " 3.83399634e-03 0.00000000e+00 3.46210968e-02 1.39750778e-03\n",
      " 7.38216315e-03 2.37471011e-04 7.67493650e-04 7.48029251e-08\n",
      " 0.00000000e+00 1.00560214e-04 7.62871967e-04 3.26204222e-03\n",
      " 9.01396698e-03 0.00000000e+00 1.49972493e-03 0.00000000e+00\n",
      " 3.45208479e-02 1.77853209e-02 6.45152763e-04 8.41433473e-03\n",
      " 3.82265346e-01 3.34489933e-04 2.13015010e-03 1.37846874e-02\n",
      " 0.00000000e+00 5.89735349e-04 1.15648350e-02 3.06893521e-03\n",
      " 0.00000000e+00 5.30863975e-04 0.00000000e+00 4.22660807e-04\n",
      " 1.21916374e-04 1.06917891e-04 1.67074542e-03 7.89053402e-05\n",
      " 5.97684998e-03 1.31064199e-03 7.37689968e-03 1.66134313e-02\n",
      " 7.49073726e-04 7.47153166e-03 3.97941569e-03 2.15304046e-03\n",
      " 2.13347655e-03 6.29116069e-03 4.19801650e-05 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.89823327e-03\n",
      " 1.42083638e-03 4.21709024e-04 3.23093061e-03 0.00000000e+00\n",
      " 0.00000000e+00 4.93754991e-04 1.06879876e-02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.28446232e-02 2.12173349e-03\n",
      " 1.52932761e-02 7.45191950e-04 8.18873158e-03 2.43906646e-03\n",
      " 2.18244333e-03 3.71368602e-03 5.05918352e-03 7.58196865e-03\n",
      " 1.82909304e-02 1.09319048e-03 0.00000000e+00 8.74716023e-08\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.11068016e-02\n",
      " 8.30970278e-03 3.93208370e-04]\n",
      "XGBClassifier\n",
      "[0.00469814 0.00468051 0.08402461 0.01089205 0.         0.0045744\n",
      " 0.01488221 0.00450611 0.00602965 0.00855677 0.00685373 0.00939542\n",
      " 0.         0.         0.02131581 0.0072687  0.00855973 0.00659085\n",
      " 0.00967363 0.00996205 0.00431754 0.00628961 0.00481748 0.00853033\n",
      " 0.00907715 0.         0.         0.         0.02049905 0.00835332\n",
      " 0.00737692 0.01349315 0.33470047 0.00560759 0.00458002 0.01005511\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00629414 0.00736708\n",
      " 0.01595566 0.00640319 0.00760755 0.01173131 0.00366268 0.\n",
      " 0.         0.00520927 0.00501367 0.00705051 0.00778606 0.\n",
      " 0.00569602 0.00234542 0.         0.00449868 0.00799381 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01141023 0.00659857 0.01256451 0.0091356\n",
      " 0.01355365 0.01084323 0.00822332 0.00470051 0.01912024 0.01256437\n",
      " 0.03536947 0.         0.01083809 0.00500946 0.         0.\n",
      " 0.         0.05938435 0.00798186 0.00792534]\n"
     ]
    }
   ],
   "source": [
    "for alg in tree_models:\n",
    "    try:\n",
    "        print(alg.__class__.__name__)\n",
    "        print(alg.feature_importances_)\n",
    "    except:\n",
    "        print(alg.__class__.__name__, \"X\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 중요도 기반 데이터프레임 작성하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "random_model_importance = pd.DataFrame({'Feature':X_train.columns, 'random_model':random_model.feature_importances_})\n",
    "extra_model_importance = pd.DataFrame({'Feature':X_train.columns, 'extra_model':extra_model.feature_importances_})\n",
    "gbm_model_importance = pd.DataFrame({'Feature':X_train.columns, 'gbm_model':gbm_model.feature_importances_})\n",
    "xgb_model_importance = pd.DataFrame({'Feature':X_train.columns, 'xgb_model':xgb_model.feature_importances_})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### multiple dataframe 합치기\n",
    "- dataframes = [각 데이터프레임, ...]\n",
    "- functools.reduce(lambda  left,right: pd.merge(left, right, on=['동일컬럼']), dataframes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "data_frames = [\n",
    "    random_model_importance,\n",
    "    extra_model_importance,\n",
    "    gbm_model_importance,\n",
    "    xgb_model_importance\n",
    "]\n",
    "importances = reduce(lambda  left,right: pd.merge(left, right, on=['Feature']), data_frames)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "    Feature  random_model  extra_model  gbm_model  xgb_model\n0  Pclass_0      0.014715     0.018555   0.014408   0.004698\n1  Pclass_1      0.015021     0.017881   0.000000   0.004681\n2  Pclass_2      0.035811     0.035470   0.114703   0.084025\n3     Sex_0      0.070095     0.060969   0.028755   0.010892\n4     Sex_1      0.056470     0.085870   0.084164   0.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>random_model</th>\n      <th>extra_model</th>\n      <th>gbm_model</th>\n      <th>xgb_model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Pclass_0</td>\n      <td>0.014715</td>\n      <td>0.018555</td>\n      <td>0.014408</td>\n      <td>0.004698</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Pclass_1</td>\n      <td>0.015021</td>\n      <td>0.017881</td>\n      <td>0.000000</td>\n      <td>0.004681</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pclass_2</td>\n      <td>0.035811</td>\n      <td>0.035470</td>\n      <td>0.114703</td>\n      <td>0.084025</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sex_0</td>\n      <td>0.070095</td>\n      <td>0.060969</td>\n      <td>0.028755</td>\n      <td>0.010892</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sex_1</td>\n      <td>0.056470</td>\n      <td>0.085870</td>\n      <td>0.084164</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 항목별 평균 중요도 구하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "importances['avg'] = importances.mean(axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 중요도 기반 정렬하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "importances = importances.sort_values(by='avg', ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 중요도가 높은 feature 만 선택하기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "importances = importances[:50]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 특정 컬럼만 선택해서, 데이터프레임 만들기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "train_importance = X_train[importances['Feature'].tolist()]\n",
    "test_importance = X_test[importances['Feature'].tolist()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "   Initial_0  Pclass_2  Sex_1  Sex_0  LowChance_0  HighChance_0  Cabin_8  \\\n0          1         1      0      1            1             1        1   \n1          0         0      1      0            1             0        0   \n2          0         1      1      0            1             1        1   \n3          0         0      1      0            1             0        0   \n4          1         1      0      1            0             1        1   \n\n   Fare_0  Ticket_Num_Cut_2  Embarked_0  ...  Cabin_3  Family_4  \\\n0       1                 0           1  ...        0         0   \n1       0                 0           0  ...        0         0   \n2       1                 0           1  ...        0         0   \n3       0                 0           1  ...        0         0   \n4       1                 0           1  ...        0         0   \n\n   Ticket_Num_Cut_6  Ticket_Num_Cut_3  HighChance_3  HighChance_2  \\\n0                 0                 1             0             0   \n1                 0                 1             0             1   \n2                 0                 0             0             0   \n3                 0                 0             0             1   \n4                 0                 0             0             0   \n\n   Ticket_initial2_2  Fare_5  Family_3  Cabin_1  \n0                  0       0         0        0  \n1                  0       0         0        0  \n2                  1       0         0        0  \n3                  0       0         0        0  \n4                  0       0         0        0  \n\n[5 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Initial_0</th>\n      <th>Pclass_2</th>\n      <th>Sex_1</th>\n      <th>Sex_0</th>\n      <th>LowChance_0</th>\n      <th>HighChance_0</th>\n      <th>Cabin_8</th>\n      <th>Fare_0</th>\n      <th>Ticket_Num_Cut_2</th>\n      <th>Embarked_0</th>\n      <th>...</th>\n      <th>Cabin_3</th>\n      <th>Family_4</th>\n      <th>Ticket_Num_Cut_6</th>\n      <th>Ticket_Num_Cut_3</th>\n      <th>HighChance_3</th>\n      <th>HighChance_2</th>\n      <th>Ticket_initial2_2</th>\n      <th>Fare_5</th>\n      <th>Family_3</th>\n      <th>Cabin_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 50 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_importance.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 중요도가 높은 feature 로만 머신러닝 적용해보기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "logreg_model = LogisticRegression()\n",
    "svc_model = SVC()\n",
    "decision_model = DecisionTreeClassifier()\n",
    "random_model = RandomForestClassifier()\n",
    "extra_model = ExtraTreesClassifier()\n",
    "gbm_model = GradientBoostingClassifier()\n",
    "nb_model = GaussianNB()\n",
    "xgb_model = XGBClassifier(eval_metric='logloss')\n",
    "lgbm_model = LGBMClassifier()\n",
    "\n",
    "models = [\n",
    "    knn_model,\n",
    "    logreg_model,\n",
    "    svc_model,\n",
    "    decision_model,\n",
    "    random_model,\n",
    "    extra_model,\n",
    "    gbm_model,\n",
    "    nb_model,\n",
    "    xgb_model,\n",
    "    lgbm_model\n",
    "]\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)           # K-Fold 사용\n",
    "results = dict()\n",
    "for alg in models:\n",
    "    alg.fit(train_importance, y_train)\n",
    "    score = cross_val_score(alg, train_importance, y_train.values.ravel(), cv=k_fold, scoring='accuracy')\n",
    "    results[alg.__class__.__name__] = np.mean(score)*100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "[('LogisticRegression', 83.16354556803994),\n ('GradientBoostingClassifier', 82.82646691635455),\n ('SVC', 82.71535580524345),\n ('ExtraTreesClassifier', 82.48689138576779),\n ('RandomForestClassifier', 82.37578027465666),\n ('KNeighborsClassifier', 82.15480649188515),\n ('XGBClassifier', 82.15230961298377),\n ('LGBMClassifier', 81.81523096129837),\n ('DecisionTreeClassifier', 80.24469413233459),\n ('GaussianNB', 78.66541822721598)]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(results.items(), key=lambda x: x[1], reverse=True) # reverse=True 면 높은 순서대로 정렬"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('titanic_step4_importance_train.pickle', 'wb') as pickle_filename:\n",
    "    pickle.dump(train_importance, pickle_filename)\n",
    "with open('titanic_step4_importance_test.pickle', 'wb') as pickle_filename:\n",
    "    pickle.dump(test_importance, pickle_filename)\n",
    "with open('titanic_step4_importance_train_y.pickle', 'wb') as pickle_filename:\n",
    "    pickle.dump(y_train, pickle_filename)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
