{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('titanic_step4_importance_train.pickle', 'rb') as pickle_filename:\n",
    "    train_importance = pickle.load(pickle_filename)\n",
    "with open('titanic_step4_importance_test.pickle', 'rb') as pickle_filename:\n",
    "    test_importance = pickle.load(pickle_filename)\n",
    "with open('titanic_step4_importance_train_y.pickle', 'rb') as pickle_filename:\n",
    "    train_answer = pickle.load(pickle_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier # 1. KNN\n",
    "from sklearn.linear_model import LogisticRegression # 2. Logistic\n",
    "from sklearn.svm import SVC # 3. SVC\n",
    "from sklearn.tree import DecisionTreeClassifier # 4. Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier # 5. Random Forest\n",
    "from sklearn.ensemble import ExtraTreesClassifier # 6. Extra Tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier # 7.GBM\n",
    "from sklearn.naive_bayes import GaussianNB # 8. GaussianNB\n",
    "from xgboost import XGBClassifier # 9. Xgboost\n",
    "from lightgbm import LGBMClassifier # 10. lightgbm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 하이퍼 파라미터 튜닝과 SVC\n",
    "- SVC 는 결국 분류의 경계가 되는 경계선을 작성하여, 분류를 실행하는 모델\n",
    "- 해당 경계선을 일직선으로 할지, 어느 정도 곡률을 가진 선으로 할지도 선정 가능\n",
    "- 주요 하이퍼 파라미터\n",
    "  - C : regularization 파라미터\n",
    "  - gamma: 어느 정도 훈련 셋에 fit 하게 할지를 결정"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RandomizedSearchCV + SVC\n",
    "- RandomizedSearchCV() 는 랜덤하게 파라미터값을 선정하여, 테스트를 수행하므로,\n",
    "- 보다 적합한 파라미터값을 도출하기 위해서는 수행횟수를 늘려야 함\n",
    "- 따라서 머신러닝 모델의 수행성능에 따라, RandomizedSearchCV() 사용시, 수행시간이 상당히 오래 걸릴 수 있으므로,\n",
    "- RandomizedSearchCV() 이해를 위해서만 일부 모델에서만 테스트를 진행하고,\n",
    "- GridSearchCV() 을 주로 사용하기로 함"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 참고: 균일 분포 또는 균등 분포(Uniform Distribution)\n",
    "  - 정해진 범위에서 모든 확률이 균일한 분포를 의미함\n",
    "  - 균일 분포는 이산형 확률 분포와 연속형 확률 분포 두 형태가 존재\n",
    "  - 연속형 확률 분포: 두 점 a,b 사이의 연속적인 값에 대한 확률 분포\n",
    "  - 이산형 확률 분포: 두 점 a,b 사이에 갯수가 정해진 값들에 대한 확률 분포"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### stats.uniform(loc, scale)\n",
    "- loc 부터, loc + scale 까지의 범위에서 균등한 확률로 연속형 값을 추출\n",
    "- 해당 객체는 rvs() 메서드를 가지고 있고, 이를 사용해서, RandomizedSearchCV() 가 랜덤 값을 균등 확률로 추출해서, 적용 및 테스트"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8372795179210344\n",
      "{'C': 2.995884475610583, 'gamma': 0.12134345574073735}\n",
      "                                               params  mean_test_score\n",
      "0   {'C': 20.8511002351287, 'gamma': 0.72032449344...         0.820451\n",
      "1   {'C': 0.005718740867244332, 'gamma': 0.3023325...         0.616163\n",
      "2   {'C': 7.337794540855652, 'gamma': 0.0923385947...         0.836162\n",
      "3   {'C': 9.313010568883545, 'gamma': 0.3455607270...         0.821549\n",
      "4   {'C': 19.838373711533496, 'gamma': 0.538816734...         0.822685\n",
      "..                                                ...              ...\n",
      "95  {'C': 13.164838524355549, 'gamma': 0.065961090...         0.836168\n",
      "96  {'C': 36.753298164433474, 'gamma': 0.772178029...         0.814839\n",
      "97  {'C': 45.3907926251762, 'gamma': 0.93197206919...         0.805875\n",
      "98  {'C': 0.6975786487798508, 'gamma': 0.234362086...         0.831643\n",
      "99  {'C': 30.83891785008288, 'gamma': 0.9490163206...         0.805875\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {\n",
    "    \"C\": stats.uniform(0, 50),\n",
    "    \"gamma\": stats.uniform(0, 1)\n",
    "}\n",
    "gd = RandomizedSearchCV(\n",
    "    estimator=SVC(random_state=1),\n",
    "    param_distributions=hyperparams,\n",
    "    n_iter=100,\n",
    "    cv=5, # 내부적으로 Stratified K Fold 사용\n",
    "    scoring='accuracy',\n",
    "    random_state=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gd.fit(train_importance, train_answer.values.ravel())\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)\n",
    "\n",
    "df = pd.DataFrame(gd.cv_results_)\n",
    "print(df[['params', 'mean_test_score']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVC + 하이퍼 파라미터 튜닝 (GridSearchCV 사용)\n",
    "> 하이퍼파라미터는 일반적으로 적절한 범위가 없기 때문에, 각 데이터에 맞춰서 성능이 나오는 범위를 감으로 지정해야 함\n",
    "> RandomizedSearchCV() 를 통해, 대략적인 범위를 알아낸 후, 이를 기반으로 GridSearchCV() 를 사용하여\n",
    "> 범위와, 최적의 값을 가질 수 있는 후보군을 지정하는 방식으로, 최적의 하이퍼파라미터 값을 찾아가는 방법을 많이 사용함"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "0.8372920720607621\n",
      "{'C': 15, 'gamma': 0.06}\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 그리드 셋팅\n",
    "hyperparams = {\n",
    "    'C': [10, 15, 20, 23, 25, 30, 50],\n",
    "    'gamma': [0.001, 0.01, 0.05, 0.06, 0.07, 0.08]\n",
    "}\n",
    "\n",
    "# 교차 검증\n",
    "gd = GridSearchCV(\n",
    "    estimator=SVC(random_state=1),\n",
    "    param_grid=hyperparams,\n",
    "    verbose=True,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gd.fit(train_importance, train_answer.values.ravel())\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Gradient Boosting Classifier 주요 하이퍼 파라미터\n",
    "- learning_rate는 학습률을 의미하며, 각 트리의 오류에 기반해서, 어느 정도 수정할지의 비율을 의미\n",
    "- n_estimator 는 트리의 갯수를 의미\n",
    "- max_depth 는 트리의 깊이를 의미"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradient Boosting Classifier + 하이퍼 파라미터 튜닝 (GridSearchCV 사용)\n",
    "- Gradient Boosting Classifier 는 수행시간이 오래 걸리므로, RandomizedSearchCV() 로 사전 테스트를 통해, 대략적인 최적의 파라미터값을 예상하여, GridSearchCV() 로 테스트"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "0.8406377502981608\n",
      "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "learning_rate=[0.01, 0.05, 0.1, 0.2]\n",
    "n_estimators=[100, 1000, 2000]\n",
    "max_depth=[3, 5, 10, 15]\n",
    "\n",
    "hyperparams = {\n",
    "    'learning_rate': learning_rate,\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth': max_depth\n",
    "}\n",
    "\n",
    "gd = GridSearchCV(\n",
    "    estimator=GradientBoostingClassifier(random_state=1),\n",
    "    param_grid=hyperparams,\n",
    "    verbose=True,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gd.fit(train_importance, train_answer.values.ravel())\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Logistic Regression 주요 하이퍼 파라미터\n",
    "* penalty: regularization 종류 선정 (l1, l2 등)\n",
    "* C: regularization 적용 강도"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression + 하이퍼 파라미터 튜닝 (RandomizedSearchCV 사용)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8384282217061075\n",
      "{'C': 18.288277344191805, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "hyperparams = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'C': stats.uniform(0, 1000)\n",
    "}\n",
    "gd = RandomizedSearchCV(\n",
    "    estimator=LogisticRegression(random_state=1, solver='lbfgs', max_iter=1000),\n",
    "    param_distributions=hyperparams,\n",
    "    n_iter=100,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    random_state=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "gd.fit(train_importance, train_answer.values.ravel())\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression + 하이퍼 파라미터 튜닝 (GridSearchCV 사용)\n",
    "- numpy.linspace(start, end, num)\n",
    "  - start ~ end 사이의 값을 등간격으로 num 갯수만큼의 배열을 생성하는 numpy 메서드"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n",
      "0.8372983491306257\n",
      "{'C': 700.0, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "np.linspace(700, 900, 10)\n",
    "\n",
    "penalty = ['l1', 'l2']\n",
    "C = np.linspace(700, 900, 200)\n",
    "\n",
    "hyperparams = {\n",
    "    'penalty': penalty,\n",
    "    'C': C\n",
    "}\n",
    "\n",
    "gd=GridSearchCV(\n",
    "    # 2022.12.22 해당 라이브러리 변경으로 인터페이스가 변경되어,  기존 코드로 경고표시가 나옵니다.\n",
    "    #  경고표시가 나오더라도, 진행에는 문제가 없지만, 당황하실 수 있어서, 경고표시가 나오지 않도록 코드를 업데이트합니다.\n",
    "    # estimator = LogisticRegression(random_state=1)\n",
    "    estimator = LogisticRegression(random_state=1, solver='lbfgs', max_iter=1000),\n",
    "    param_grid = hyperparams,\n",
    "    verbose=True,\n",
    "    cv=5,\n",
    "    scoring = \"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "# 2022.12.22 해당 라이브러리 변경으로 인터페이스가 변경되어,  기존 코드로 경고표시가 나옵니다.\n",
    "#  경고표시가 나오더라도, 진행에는 문제가 없지만, 당황하실 수 있어서, 경고표시가 나오지 않도록 코드를 업데이트합니다.\n",
    "# gd.fit(train_importance, train_answer)\n",
    "gd.fit(train_importance, train_answer.values.ravel())\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. XGBoost 와 주요 하이퍼 파라미터\n",
    "- 일반적인 XGBoost 하이퍼 파라미터 튜닝 전략\n",
    "   - ensemble 방식은 수행시, 각 파라미터를 적절히 맞춰주기 때문에, 하이퍼 파라미터 튜닝이 정확도를 높이는데 있어서, 큰 기여를 하는 편은 아니며,\n",
    "   - 무수히 많은 파라미터가 있고, 수행 시간이 오래 걸리므로, 주요한 파라미터들만 중심으로 튜닝을 진행하는 편이 좋음\n",
    "- 성능에 영향을 많이 끼치는 주요 파라미터\n",
    "   - learning_rate\n",
    "      - 이전 결과를 얼마나 반영할지에 대한 학습 단계별 적용할 가중치를 의미함\n",
    "      - 일반적으로 0.01 ~ 0.2 사이의 값을 많이 사용함\n",
    "   - max_depth\n",
    "      - 트리의 최대 깊이를 의미함\n",
    "      - 트리의 최대 깊이로 -1 로 하면, 깊이에 제한을 두지 않음\n",
    "      - 일반적으로 3 ~ 10 사이의 값을 많이 사용함\n",
    "   - gamma\n",
    "      - 일종의 정규화(regularization) 파라미터로, gamma 가 높을 수록, regularization 이 높다고 이해하면 됨\n",
    "      - 트리에서 가지를 추가로 만들기 위해 필요한 최소 loss 기준값으로, gamma 값이 작으면, 트리에 보다 많은 가지가 만들어진다고 이해하면 됨\n",
    "      - 일반적으로 0 이상의 값을 가짐\n",
    "   - min_child_weight\n",
    "      - 트리에서 가지를 추가로 만들어 분할하기 위해, 필요한 최소한의 샘플 수\n",
    "      - 값이 적을 수록, 트리가 더 분할될 수 있음\n",
    "      - 일반적으로 0 이상의 값을 가짐\n",
    "   - subsample\n",
    "      - 각 트리마다 모든 훈련데이터를 사용해서 트리를 만들지 않음\n",
    "      - 훈련 데이터의 일부를 사용해서 트리를 만든다면, 보다 많은 트리를 만들 수 있고, 이를 통해 트리의 다양성을 높일 수 있음\n",
    "      - subsample 은 이 때, 각 트리마다 어느 정도의 훈련 데이터 비율을 사용해서 트리를 만들지를 그 비율을 정하는 것임\n",
    "      - 일반적으로 0.5 ~ 1 사이의 값을 많이 사용함\n",
    "   - colsample_bytree\n",
    "      - subsample 과 마찬가지로, 훈련 데이터에서 일부 feature (컬럼) 들만 뽑아서 트리를 만드는 방식\n",
    "      - 일부 feature (컬럼)들만 뽑아서 트리를 만든다면, 보다 많은 트리를 만들 수 있고, 이를 통해 트리의 다양성을 높일 수 있음\n",
    "      - colsample_bytree 는 이를 위해 각 트리를 만들 때 사용할 feature의 비율을 정하는 것임\n",
    "      - 일반적으로 0.5 ~ 1 사이의 값을 많이 사용함\n",
    "\n",
    "   - reg_alpha: L1 정규화(regularization) 가중치\n",
    "   - reg_lambda: L2 정규화(regularization) 가중치"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bayesian-optimization==1.4.0\n",
      "  Downloading bayesian_optimization-1.4.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\minsu\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from bayesian-optimization==1.4.0) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in c:\\users\\minsu\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from bayesian-optimization==1.4.0) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\minsu\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from bayesian-optimization==1.4.0) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\minsu\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from scikit-learn>=0.18.0->bayesian-optimization==1.4.0) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\minsu\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from scikit-learn>=0.18.0->bayesian-optimization==1.4.0) (2.2.0)\n",
      "Installing collected packages: bayesian-optimization\n",
      "Successfully installed bayesian-optimization-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install bayesian-optimization==1.4.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bayesian Optimization XGBoost 적용"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | learni... | max_depth | min_ch... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001B[0m1        \u001B[0m | \u001B[0m0.8204   \u001B[0m | \u001B[0m0.7085   \u001B[0m | \u001B[0m3.602    \u001B[0m | \u001B[0m0.01006  \u001B[0m | \u001B[0m5.116    \u001B[0m | \u001B[0m1.468    \u001B[0m | \u001B[0m183.1    \u001B[0m | \u001B[0m0.5931   \u001B[0m |\n",
      "| \u001B[95m2        \u001B[0m | \u001B[95m0.8283   \u001B[0m | \u001B[95m0.6728   \u001B[0m | \u001B[95m1.984    \u001B[0m | \u001B[95m0.274    \u001B[0m | \u001B[95m5.934    \u001B[0m | \u001B[95m6.852    \u001B[0m | \u001B[95m284.0    \u001B[0m | \u001B[95m0.9391   \u001B[0m |\n",
      "| \u001B[95m3        \u001B[0m | \u001B[95m0.8305   \u001B[0m | \u001B[95m0.5137   \u001B[0m | \u001B[95m3.352    \u001B[0m | \u001B[95m0.2145   \u001B[0m | \u001B[95m6.911    \u001B[0m | \u001B[95m1.404    \u001B[0m | \u001B[95m278.3    \u001B[0m | \u001B[95m0.9004   \u001B[0m |\n",
      "| \u001B[0m4        \u001B[0m | \u001B[0m0.7969   \u001B[0m | \u001B[0m0.9841   \u001B[0m | \u001B[0m1.567    \u001B[0m | \u001B[0m0.3492   \u001B[0m | \u001B[0m9.135    \u001B[0m | \u001B[0m8.946    \u001B[0m | \u001B[0m176.5    \u001B[0m | \u001B[0m0.5195   \u001B[0m |\n",
      "| \u001B[0m5        \u001B[0m | \u001B[0m0.8126   \u001B[0m | \u001B[0m0.5849   \u001B[0m | \u001B[0m4.391    \u001B[0m | \u001B[0m0.05819  \u001B[0m | \u001B[0m5.948    \u001B[0m | \u001B[0m9.579    \u001B[0m | \u001B[0m579.8    \u001B[0m | \u001B[0m0.8459   \u001B[0m |\n",
      "| \u001B[0m6        \u001B[0m | \u001B[0m0.8272   \u001B[0m | \u001B[0m0.6578   \u001B[0m | \u001B[0m3.433    \u001B[0m | \u001B[0m0.419    \u001B[0m | \u001B[0m3.128    \u001B[0m | \u001B[0m7.501    \u001B[0m | \u001B[0m990.0    \u001B[0m | \u001B[0m0.8741   \u001B[0m |\n",
      "| \u001B[0m7        \u001B[0m | \u001B[0m0.8081   \u001B[0m | \u001B[0m0.6402   \u001B[0m | \u001B[0m3.946    \u001B[0m | \u001B[0m0.06058  \u001B[0m | \u001B[0m6.135    \u001B[0m | \u001B[0m9.086    \u001B[0m | \u001B[0m364.3    \u001B[0m | \u001B[0m0.6439   \u001B[0m |\n",
      "| \u001B[0m8        \u001B[0m | \u001B[0m0.8227   \u001B[0m | \u001B[0m0.565    \u001B[0m | \u001B[0m0.09683  \u001B[0m | \u001B[0m0.3426   \u001B[0m | \u001B[0m4.481    \u001B[0m | \u001B[0m2.655    \u001B[0m | \u001B[0m542.4    \u001B[0m | \u001B[0m0.5267   \u001B[0m |\n",
      "| \u001B[95m9        \u001B[0m | \u001B[95m0.8339   \u001B[0m | \u001B[95m0.7871   \u001B[0m | \u001B[95m0.7336   \u001B[0m | \u001B[95m0.2988   \u001B[0m | \u001B[95m7.898    \u001B[0m | \u001B[95m1.023    \u001B[0m | \u001B[95m472.7    \u001B[0m | \u001B[95m0.8472   \u001B[0m |\n",
      "| \u001B[0m10       \u001B[0m | \u001B[0m0.8205   \u001B[0m | \u001B[0m0.7071   \u001B[0m | \u001B[0m0.2498   \u001B[0m | \u001B[0m0.2726   \u001B[0m | \u001B[0m7.647    \u001B[0m | \u001B[0m5.149    \u001B[0m | \u001B[0m950.1    \u001B[0m | \u001B[0m0.7933   \u001B[0m |\n",
      "| \u001B[0m11       \u001B[0m | \u001B[0m0.8339   \u001B[0m | \u001B[0m0.5523   \u001B[0m | \u001B[0m1.118    \u001B[0m | \u001B[0m0.02605  \u001B[0m | \u001B[0m7.734    \u001B[0m | \u001B[0m2.317    \u001B[0m | \u001B[0m472.2    \u001B[0m | \u001B[0m0.5697   \u001B[0m |\n",
      "| \u001B[95m12       \u001B[0m | \u001B[95m0.8373   \u001B[0m | \u001B[95m0.9681   \u001B[0m | \u001B[95m3.555    \u001B[0m | \u001B[95m0.4466   \u001B[0m | \u001B[95m7.966    \u001B[0m | \u001B[95m4.643    \u001B[0m | \u001B[95m484.1    \u001B[0m | \u001B[95m0.9186   \u001B[0m |\n",
      "| \u001B[95m13       \u001B[0m | \u001B[95m0.8417   \u001B[0m | \u001B[95m0.5      \u001B[0m | \u001B[95m0.0      \u001B[0m | \u001B[95m0.01     \u001B[0m | \u001B[95m7.415    \u001B[0m | \u001B[95m0.0      \u001B[0m | \u001B[95m496.8    \u001B[0m | \u001B[95m0.5      \u001B[0m |\n",
      "| \u001B[0m14       \u001B[0m | \u001B[0m0.807    \u001B[0m | \u001B[0m1.0      \u001B[0m | \u001B[0m5.0      \u001B[0m | \u001B[0m0.5      \u001B[0m | \u001B[0m10.0     \u001B[0m | \u001B[0m10.0     \u001B[0m | \u001B[0m504.7    \u001B[0m | \u001B[0m1.0      \u001B[0m |\n",
      "| \u001B[0m15       \u001B[0m | \u001B[0m0.8205   \u001B[0m | \u001B[0m0.8693   \u001B[0m | \u001B[0m0.2458   \u001B[0m | \u001B[0m0.3796   \u001B[0m | \u001B[0m4.463    \u001B[0m | \u001B[0m0.5986   \u001B[0m | \u001B[0m489.8    \u001B[0m | \u001B[0m0.554    \u001B[0m |\n",
      "| \u001B[0m16       \u001B[0m | \u001B[0m0.8395   \u001B[0m | \u001B[0m0.6148   \u001B[0m | \u001B[0m3.879    \u001B[0m | \u001B[0m0.03072  \u001B[0m | \u001B[0m9.725    \u001B[0m | \u001B[0m0.03855  \u001B[0m | \u001B[0m496.3    \u001B[0m | \u001B[0m0.5897   \u001B[0m |\n",
      "| \u001B[0m17       \u001B[0m | \u001B[0m0.8126   \u001B[0m | \u001B[0m1.0      \u001B[0m | \u001B[0m5.0      \u001B[0m | \u001B[0m0.5      \u001B[0m | \u001B[0m10.0     \u001B[0m | \u001B[0m7.899    \u001B[0m | \u001B[0m478.3    \u001B[0m | \u001B[0m1.0      \u001B[0m |\n",
      "| \u001B[0m18       \u001B[0m | \u001B[0m0.8216   \u001B[0m | \u001B[0m0.6049   \u001B[0m | \u001B[0m1.245    \u001B[0m | \u001B[0m0.1333   \u001B[0m | \u001B[0m8.919    \u001B[0m | \u001B[0m3.957    \u001B[0m | \u001B[0m494.8    \u001B[0m | \u001B[0m0.5635   \u001B[0m |\n",
      "| \u001B[95m19       \u001B[0m | \u001B[95m0.8429   \u001B[0m | \u001B[95m0.9957   \u001B[0m | \u001B[95m2.28     \u001B[0m | \u001B[95m0.4923   \u001B[0m | \u001B[95m8.47     \u001B[0m | \u001B[95m0.3668   \u001B[0m | \u001B[95m500.2    \u001B[0m | \u001B[95m0.7079   \u001B[0m |\n",
      "| \u001B[0m20       \u001B[0m | \u001B[0m0.8283   \u001B[0m | \u001B[0m0.5752   \u001B[0m | \u001B[0m3.564    \u001B[0m | \u001B[0m0.3741   \u001B[0m | \u001B[0m5.51     \u001B[0m | \u001B[0m0.1874   \u001B[0m | \u001B[0m497.4    \u001B[0m | \u001B[0m0.7583   \u001B[0m |\n",
      "| \u001B[0m21       \u001B[0m | \u001B[0m0.8283   \u001B[0m | \u001B[0m0.691    \u001B[0m | \u001B[0m0.1552   \u001B[0m | \u001B[0m0.1024   \u001B[0m | \u001B[0m5.41     \u001B[0m | \u001B[0m1.991    \u001B[0m | \u001B[0m501.7    \u001B[0m | \u001B[0m0.7982   \u001B[0m |\n",
      "| \u001B[0m22       \u001B[0m | \u001B[0m0.8328   \u001B[0m | \u001B[0m0.6467   \u001B[0m | \u001B[0m1.548    \u001B[0m | \u001B[0m0.3506   \u001B[0m | \u001B[0m7.39     \u001B[0m | \u001B[0m0.2789   \u001B[0m | \u001B[0m482.6    \u001B[0m | \u001B[0m0.6858   \u001B[0m |\n",
      "| \u001B[0m23       \u001B[0m | \u001B[0m0.8227   \u001B[0m | \u001B[0m0.9527   \u001B[0m | \u001B[0m0.5163   \u001B[0m | \u001B[0m0.4205   \u001B[0m | \u001B[0m9.843    \u001B[0m | \u001B[0m0.3787   \u001B[0m | \u001B[0m498.5    \u001B[0m | \u001B[0m0.8729   \u001B[0m |\n",
      "| \u001B[0m24       \u001B[0m | \u001B[0m0.8249   \u001B[0m | \u001B[0m0.5507   \u001B[0m | \u001B[0m3.773    \u001B[0m | \u001B[0m0.4505   \u001B[0m | \u001B[0m8.128    \u001B[0m | \u001B[0m0.4991   \u001B[0m | \u001B[0m501.5    \u001B[0m | \u001B[0m0.7515   \u001B[0m |\n",
      "| \u001B[0m25       \u001B[0m | \u001B[0m0.8395   \u001B[0m | \u001B[0m0.5371   \u001B[0m | \u001B[0m1.048    \u001B[0m | \u001B[0m0.4405   \u001B[0m | \u001B[0m7.433    \u001B[0m | \u001B[0m0.6428   \u001B[0m | \u001B[0m499.1    \u001B[0m | \u001B[0m0.8913   \u001B[0m |\n",
      "| \u001B[0m26       \u001B[0m | \u001B[0m0.8216   \u001B[0m | \u001B[0m0.9321   \u001B[0m | \u001B[0m3.29     \u001B[0m | \u001B[0m0.2517   \u001B[0m | \u001B[0m7.738    \u001B[0m | \u001B[0m0.7375   \u001B[0m | \u001B[0m498.6    \u001B[0m | \u001B[0m0.6792   \u001B[0m |\n",
      "| \u001B[0m27       \u001B[0m | \u001B[0m0.8227   \u001B[0m | \u001B[0m0.8083   \u001B[0m | \u001B[0m0.5824   \u001B[0m | \u001B[0m0.4684   \u001B[0m | \u001B[0m6.975    \u001B[0m | \u001B[0m1.195    \u001B[0m | \u001B[0m496.2    \u001B[0m | \u001B[0m0.6413   \u001B[0m |\n",
      "| \u001B[0m28       \u001B[0m | \u001B[0m0.8328   \u001B[0m | \u001B[0m0.5383   \u001B[0m | \u001B[0m0.02626  \u001B[0m | \u001B[0m0.08691  \u001B[0m | \u001B[0m7.688    \u001B[0m | \u001B[0m1.261    \u001B[0m | \u001B[0m499.9    \u001B[0m | \u001B[0m0.7145   \u001B[0m |\n",
      "| \u001B[0m29       \u001B[0m | \u001B[0m0.8339   \u001B[0m | \u001B[0m0.8803   \u001B[0m | \u001B[0m2.712    \u001B[0m | \u001B[0m0.3801   \u001B[0m | \u001B[0m9.736    \u001B[0m | \u001B[0m1.222    \u001B[0m | \u001B[0m500.2    \u001B[0m | \u001B[0m0.9667   \u001B[0m |\n",
      "| \u001B[0m30       \u001B[0m | \u001B[0m0.8316   \u001B[0m | \u001B[0m0.6448   \u001B[0m | \u001B[0m1.27     \u001B[0m | \u001B[0m0.05223  \u001B[0m | \u001B[0m8.386    \u001B[0m | \u001B[0m1.686    \u001B[0m | \u001B[0m501.5    \u001B[0m | \u001B[0m0.6293   \u001B[0m |\n",
      "| \u001B[0m31       \u001B[0m | \u001B[0m0.835    \u001B[0m | \u001B[0m0.9089   \u001B[0m | \u001B[0m3.826    \u001B[0m | \u001B[0m0.03619  \u001B[0m | \u001B[0m6.115    \u001B[0m | \u001B[0m4.002    \u001B[0m | \u001B[0m483.2    \u001B[0m | \u001B[0m0.7883   \u001B[0m |\n",
      "| \u001B[0m32       \u001B[0m | \u001B[0m0.8328   \u001B[0m | \u001B[0m0.9421   \u001B[0m | \u001B[0m4.546    \u001B[0m | \u001B[0m0.145    \u001B[0m | \u001B[0m8.747    \u001B[0m | \u001B[0m0.0793   \u001B[0m | \u001B[0m495.9    \u001B[0m | \u001B[0m0.6948   \u001B[0m |\n",
      "| \u001B[0m33       \u001B[0m | \u001B[0m0.8328   \u001B[0m | \u001B[0m0.9936   \u001B[0m | \u001B[0m2.33     \u001B[0m | \u001B[0m0.3025   \u001B[0m | \u001B[0m9.335    \u001B[0m | \u001B[0m3.129    \u001B[0m | \u001B[0m483.7    \u001B[0m | \u001B[0m0.8846   \u001B[0m |\n",
      "| \u001B[0m34       \u001B[0m | \u001B[0m0.835    \u001B[0m | \u001B[0m0.6771   \u001B[0m | \u001B[0m2.177    \u001B[0m | \u001B[0m0.04362  \u001B[0m | \u001B[0m6.408    \u001B[0m | \u001B[0m2.659    \u001B[0m | \u001B[0m483.0    \u001B[0m | \u001B[0m0.5346   \u001B[0m |\n",
      "| \u001B[0m35       \u001B[0m | \u001B[0m0.8339   \u001B[0m | \u001B[0m0.5733   \u001B[0m | \u001B[0m4.282    \u001B[0m | \u001B[0m0.1426   \u001B[0m | \u001B[0m7.544    \u001B[0m | \u001B[0m2.626    \u001B[0m | \u001B[0m482.7    \u001B[0m | \u001B[0m0.5575   \u001B[0m |\n",
      "| \u001B[0m36       \u001B[0m | \u001B[0m0.8306   \u001B[0m | \u001B[0m0.6652   \u001B[0m | \u001B[0m3.925    \u001B[0m | \u001B[0m0.4089   \u001B[0m | \u001B[0m6.957    \u001B[0m | \u001B[0m3.13     \u001B[0m | \u001B[0m484.9    \u001B[0m | \u001B[0m0.9395   \u001B[0m |\n",
      "| \u001B[0m37       \u001B[0m | \u001B[0m0.8238   \u001B[0m | \u001B[0m0.9024   \u001B[0m | \u001B[0m0.8418   \u001B[0m | \u001B[0m0.2611   \u001B[0m | \u001B[0m6.36     \u001B[0m | \u001B[0m4.689    \u001B[0m | \u001B[0m483.9    \u001B[0m | \u001B[0m0.9905   \u001B[0m |\n",
      "| \u001B[0m38       \u001B[0m | \u001B[0m0.8373   \u001B[0m | \u001B[0m0.7902   \u001B[0m | \u001B[0m2.325    \u001B[0m | \u001B[0m0.03238  \u001B[0m | \u001B[0m7.509    \u001B[0m | \u001B[0m2.567    \u001B[0m | \u001B[0m480.8    \u001B[0m | \u001B[0m0.8472   \u001B[0m |\n",
      "| \u001B[0m39       \u001B[0m | \u001B[0m0.8317   \u001B[0m | \u001B[0m0.8717   \u001B[0m | \u001B[0m2.362    \u001B[0m | \u001B[0m0.1827   \u001B[0m | \u001B[0m9.125    \u001B[0m | \u001B[0m4.679    \u001B[0m | \u001B[0m481.8    \u001B[0m | \u001B[0m0.9232   \u001B[0m |\n",
      "| \u001B[0m40       \u001B[0m | \u001B[0m0.8305   \u001B[0m | \u001B[0m0.81     \u001B[0m | \u001B[0m4.109    \u001B[0m | \u001B[0m0.3518   \u001B[0m | \u001B[0m5.669    \u001B[0m | \u001B[0m1.848    \u001B[0m | \u001B[0m480.4    \u001B[0m | \u001B[0m0.5389   \u001B[0m |\n",
      "| \u001B[0m41       \u001B[0m | \u001B[0m0.8182   \u001B[0m | \u001B[0m0.5418   \u001B[0m | \u001B[0m4.91     \u001B[0m | \u001B[0m0.3829   \u001B[0m | \u001B[0m7.899    \u001B[0m | \u001B[0m6.684    \u001B[0m | \u001B[0m484.5    \u001B[0m | \u001B[0m0.7939   \u001B[0m |\n",
      "| \u001B[0m42       \u001B[0m | \u001B[0m0.8361   \u001B[0m | \u001B[0m0.5182   \u001B[0m | \u001B[0m2.595    \u001B[0m | \u001B[0m0.01991  \u001B[0m | \u001B[0m9.365    \u001B[0m | \u001B[0m0.3341   \u001B[0m | \u001B[0m481.0    \u001B[0m | \u001B[0m0.7627   \u001B[0m |\n",
      "| \u001B[0m43       \u001B[0m | \u001B[0m0.8294   \u001B[0m | \u001B[0m1.0      \u001B[0m | \u001B[0m3.383    \u001B[0m | \u001B[0m0.5      \u001B[0m | \u001B[0m9.154    \u001B[0m | \u001B[0m2.157    \u001B[0m | \u001B[0m481.2    \u001B[0m | \u001B[0m1.0      \u001B[0m |\n",
      "| \u001B[0m44       \u001B[0m | \u001B[0m0.835    \u001B[0m | \u001B[0m0.6288   \u001B[0m | \u001B[0m3.053    \u001B[0m | \u001B[0m0.03136  \u001B[0m | \u001B[0m7.694    \u001B[0m | \u001B[0m0.8231   \u001B[0m | \u001B[0m480.1    \u001B[0m | \u001B[0m0.9066   \u001B[0m |\n",
      "| \u001B[0m45       \u001B[0m | \u001B[0m0.8395   \u001B[0m | \u001B[0m0.5      \u001B[0m | \u001B[0m0.0      \u001B[0m | \u001B[0m0.01     \u001B[0m | \u001B[0m6.477    \u001B[0m | \u001B[0m0.0      \u001B[0m | \u001B[0m498.2    \u001B[0m | \u001B[0m0.5      \u001B[0m |\n",
      "| \u001B[0m46       \u001B[0m | \u001B[0m0.8238   \u001B[0m | \u001B[0m0.5328   \u001B[0m | \u001B[0m0.9595   \u001B[0m | \u001B[0m0.4344   \u001B[0m | \u001B[0m8.101    \u001B[0m | \u001B[0m2.367    \u001B[0m | \u001B[0m479.6    \u001B[0m | \u001B[0m0.508    \u001B[0m |\n",
      "| \u001B[0m47       \u001B[0m | \u001B[0m0.8317   \u001B[0m | \u001B[0m0.637    \u001B[0m | \u001B[0m3.042    \u001B[0m | \u001B[0m0.03279  \u001B[0m | \u001B[0m6.344    \u001B[0m | \u001B[0m4.949    \u001B[0m | \u001B[0m481.4    \u001B[0m | \u001B[0m0.976    \u001B[0m |\n",
      "| \u001B[0m48       \u001B[0m | \u001B[0m0.8395   \u001B[0m | \u001B[0m0.7067   \u001B[0m | \u001B[0m2.439    \u001B[0m | \u001B[0m0.4506   \u001B[0m | \u001B[0m9.024    \u001B[0m | \u001B[0m1.004    \u001B[0m | \u001B[0m471.0    \u001B[0m | \u001B[0m0.9403   \u001B[0m |\n",
      "| \u001B[0m49       \u001B[0m | \u001B[0m0.8317   \u001B[0m | \u001B[0m0.9046   \u001B[0m | \u001B[0m1.068    \u001B[0m | \u001B[0m0.08757  \u001B[0m | \u001B[0m7.677    \u001B[0m | \u001B[0m0.9421   \u001B[0m | \u001B[0m469.6    \u001B[0m | \u001B[0m0.7058   \u001B[0m |\n",
      "| \u001B[0m50       \u001B[0m | \u001B[0m0.835    \u001B[0m | \u001B[0m0.8776   \u001B[0m | \u001B[0m3.61     \u001B[0m | \u001B[0m0.1773   \u001B[0m | \u001B[0m8.967    \u001B[0m | \u001B[0m2.593    \u001B[0m | \u001B[0m470.8    \u001B[0m | \u001B[0m0.9574   \u001B[0m |\n",
      "| \u001B[0m51       \u001B[0m | \u001B[0m0.8406   \u001B[0m | \u001B[0m0.9988   \u001B[0m | \u001B[0m3.517    \u001B[0m | \u001B[0m0.244    \u001B[0m | \u001B[0m9.747    \u001B[0m | \u001B[0m0.5315   \u001B[0m | \u001B[0m469.5    \u001B[0m | \u001B[0m0.587    \u001B[0m |\n",
      "| \u001B[0m52       \u001B[0m | \u001B[0m0.8317   \u001B[0m | \u001B[0m0.6007   \u001B[0m | \u001B[0m3.546    \u001B[0m | \u001B[0m0.4823   \u001B[0m | \u001B[0m8.445    \u001B[0m | \u001B[0m1.109    \u001B[0m | \u001B[0m468.8    \u001B[0m | \u001B[0m0.9779   \u001B[0m |\n",
      "| \u001B[0m53       \u001B[0m | \u001B[0m0.8316   \u001B[0m | \u001B[0m0.8804   \u001B[0m | \u001B[0m4.479    \u001B[0m | \u001B[0m0.3175   \u001B[0m | \u001B[0m9.423    \u001B[0m | \u001B[0m0.04648  \u001B[0m | \u001B[0m473.1    \u001B[0m | \u001B[0m0.9256   \u001B[0m |\n",
      "| \u001B[0m54       \u001B[0m | \u001B[0m0.8305   \u001B[0m | \u001B[0m0.6024   \u001B[0m | \u001B[0m4.344    \u001B[0m | \u001B[0m0.2485   \u001B[0m | \u001B[0m9.87     \u001B[0m | \u001B[0m0.2158   \u001B[0m | \u001B[0m493.2    \u001B[0m | \u001B[0m0.9376   \u001B[0m |\n",
      "| \u001B[0m55       \u001B[0m | \u001B[0m0.8395   \u001B[0m | \u001B[0m0.7346   \u001B[0m | \u001B[0m2.025    \u001B[0m | \u001B[0m0.433    \u001B[0m | \u001B[0m9.449    \u001B[0m | \u001B[0m0.4693   \u001B[0m | \u001B[0m469.9    \u001B[0m | \u001B[0m0.9126   \u001B[0m |\n",
      "| \u001B[0m56       \u001B[0m | \u001B[0m0.8362   \u001B[0m | \u001B[0m0.7799   \u001B[0m | \u001B[0m1.708    \u001B[0m | \u001B[0m0.3039   \u001B[0m | \u001B[0m9.845    \u001B[0m | \u001B[0m2.426    \u001B[0m | \u001B[0m470.5    \u001B[0m | \u001B[0m0.653    \u001B[0m |\n",
      "| \u001B[0m57       \u001B[0m | \u001B[0m0.8317   \u001B[0m | \u001B[0m0.6014   \u001B[0m | \u001B[0m3.541    \u001B[0m | \u001B[0m0.3781   \u001B[0m | \u001B[0m5.872    \u001B[0m | \u001B[0m0.3937   \u001B[0m | \u001B[0m472.5    \u001B[0m | \u001B[0m0.6713   \u001B[0m |\n",
      "| \u001B[0m58       \u001B[0m | \u001B[0m0.8272   \u001B[0m | \u001B[0m0.8541   \u001B[0m | \u001B[0m1.397    \u001B[0m | \u001B[0m0.1545   \u001B[0m | \u001B[0m9.83     \u001B[0m | \u001B[0m4.656    \u001B[0m | \u001B[0m473.0    \u001B[0m | \u001B[0m0.7936   \u001B[0m |\n",
      "| \u001B[0m59       \u001B[0m | \u001B[0m0.8361   \u001B[0m | \u001B[0m1.0      \u001B[0m | \u001B[0m2.797    \u001B[0m | \u001B[0m0.01     \u001B[0m | \u001B[0m10.0     \u001B[0m | \u001B[0m0.0      \u001B[0m | \u001B[0m471.1    \u001B[0m | \u001B[0m0.5      \u001B[0m |\n",
      "| \u001B[0m60       \u001B[0m | \u001B[0m0.8294   \u001B[0m | \u001B[0m0.777    \u001B[0m | \u001B[0m0.7525   \u001B[0m | \u001B[0m0.111    \u001B[0m | \u001B[0m4.091    \u001B[0m | \u001B[0m3.53     \u001B[0m | \u001B[0m472.3    \u001B[0m | \u001B[0m0.5002   \u001B[0m |\n",
      "| \u001B[0m61       \u001B[0m | \u001B[0m0.8238   \u001B[0m | \u001B[0m0.8854   \u001B[0m | \u001B[0m0.709    \u001B[0m | \u001B[0m0.3024   \u001B[0m | \u001B[0m9.45     \u001B[0m | \u001B[0m2.97     \u001B[0m | \u001B[0m466.1    \u001B[0m | \u001B[0m0.9148   \u001B[0m |\n",
      "| \u001B[0m62       \u001B[0m | \u001B[0m0.8361   \u001B[0m | \u001B[0m0.6622   \u001B[0m | \u001B[0m4.458    \u001B[0m | \u001B[0m0.4531   \u001B[0m | \u001B[0m9.898    \u001B[0m | \u001B[0m1.239    \u001B[0m | \u001B[0m470.8    \u001B[0m | \u001B[0m0.9751   \u001B[0m |\n",
      "| \u001B[0m63       \u001B[0m | \u001B[0m0.8373   \u001B[0m | \u001B[0m0.913    \u001B[0m | \u001B[0m2.088    \u001B[0m | \u001B[0m0.02464  \u001B[0m | \u001B[0m3.056    \u001B[0m | \u001B[0m2.02     \u001B[0m | \u001B[0m482.4    \u001B[0m | \u001B[0m0.8402   \u001B[0m |\n",
      "| \u001B[0m64       \u001B[0m | \u001B[0m0.8283   \u001B[0m | \u001B[0m0.5078   \u001B[0m | \u001B[0m3.303    \u001B[0m | \u001B[0m0.1856   \u001B[0m | \u001B[0m3.066    \u001B[0m | \u001B[0m3.304    \u001B[0m | \u001B[0m483.4    \u001B[0m | \u001B[0m0.5422   \u001B[0m |\n",
      "| \u001B[0m65       \u001B[0m | \u001B[0m0.8294   \u001B[0m | \u001B[0m0.8806   \u001B[0m | \u001B[0m1.259    \u001B[0m | \u001B[0m0.2099   \u001B[0m | \u001B[0m4.445    \u001B[0m | \u001B[0m0.7512   \u001B[0m | \u001B[0m479.9    \u001B[0m | \u001B[0m0.556    \u001B[0m |\n",
      "| \u001B[0m66       \u001B[0m | \u001B[0m0.8294   \u001B[0m | \u001B[0m0.8027   \u001B[0m | \u001B[0m4.208    \u001B[0m | \u001B[0m0.01329  \u001B[0m | \u001B[0m9.344    \u001B[0m | \u001B[0m0.1733   \u001B[0m | \u001B[0m484.4    \u001B[0m | \u001B[0m0.8175   \u001B[0m |\n",
      "| \u001B[0m67       \u001B[0m | \u001B[0m0.8294   \u001B[0m | \u001B[0m0.7096   \u001B[0m | \u001B[0m1.112    \u001B[0m | \u001B[0m0.4705   \u001B[0m | \u001B[0m3.462    \u001B[0m | \u001B[0m0.9529   \u001B[0m | \u001B[0m483.8    \u001B[0m | \u001B[0m0.9246   \u001B[0m |\n",
      "| \u001B[0m68       \u001B[0m | \u001B[0m0.8317   \u001B[0m | \u001B[0m0.7344   \u001B[0m | \u001B[0m4.128    \u001B[0m | \u001B[0m0.185    \u001B[0m | \u001B[0m6.431    \u001B[0m | \u001B[0m3.82     \u001B[0m | \u001B[0m472.4    \u001B[0m | \u001B[0m0.9516   \u001B[0m |\n",
      "| \u001B[0m69       \u001B[0m | \u001B[0m0.835    \u001B[0m | \u001B[0m0.8004   \u001B[0m | \u001B[0m2.237    \u001B[0m | \u001B[0m0.3542   \u001B[0m | \u001B[0m3.229    \u001B[0m | \u001B[0m3.425    \u001B[0m | \u001B[0m479.4    \u001B[0m | \u001B[0m0.7939   \u001B[0m |\n",
      "| \u001B[0m70       \u001B[0m | \u001B[0m0.8126   \u001B[0m | \u001B[0m0.8729   \u001B[0m | \u001B[0m0.2254   \u001B[0m | \u001B[0m0.4983   \u001B[0m | \u001B[0m3.253    \u001B[0m | \u001B[0m4.262    \u001B[0m | \u001B[0m480.6    \u001B[0m | \u001B[0m0.9193   \u001B[0m |\n",
      "| \u001B[0m71       \u001B[0m | \u001B[0m0.8261   \u001B[0m | \u001B[0m0.8395   \u001B[0m | \u001B[0m4.331    \u001B[0m | \u001B[0m0.4218   \u001B[0m | \u001B[0m3.91     \u001B[0m | \u001B[0m4.271    \u001B[0m | \u001B[0m478.9    \u001B[0m | \u001B[0m0.6767   \u001B[0m |\n",
      "| \u001B[0m72       \u001B[0m | \u001B[0m0.8328   \u001B[0m | \u001B[0m0.7871   \u001B[0m | \u001B[0m3.401    \u001B[0m | \u001B[0m0.1408   \u001B[0m | \u001B[0m4.336    \u001B[0m | \u001B[0m0.2234   \u001B[0m | \u001B[0m482.0    \u001B[0m | \u001B[0m0.8977   \u001B[0m |\n",
      "| \u001B[0m73       \u001B[0m | \u001B[0m0.8406   \u001B[0m | \u001B[0m0.8907   \u001B[0m | \u001B[0m1.94     \u001B[0m | \u001B[0m0.2661   \u001B[0m | \u001B[0m3.111    \u001B[0m | \u001B[0m1.129    \u001B[0m | \u001B[0m476.1    \u001B[0m | \u001B[0m0.8733   \u001B[0m |\n",
      "| \u001B[0m74       \u001B[0m | \u001B[0m0.8317   \u001B[0m | \u001B[0m0.9914   \u001B[0m | \u001B[0m3.428    \u001B[0m | \u001B[0m0.06045  \u001B[0m | \u001B[0m3.132    \u001B[0m | \u001B[0m2.037    \u001B[0m | \u001B[0m475.0    \u001B[0m | \u001B[0m0.6613   \u001B[0m |\n",
      "| \u001B[0m75       \u001B[0m | \u001B[0m0.8272   \u001B[0m | \u001B[0m0.8778   \u001B[0m | \u001B[0m0.9831   \u001B[0m | \u001B[0m0.4479   \u001B[0m | \u001B[0m3.234    \u001B[0m | \u001B[0m2.588    \u001B[0m | \u001B[0m475.4    \u001B[0m | \u001B[0m0.739    \u001B[0m |\n",
      "| \u001B[0m76       \u001B[0m | \u001B[0m0.8339   \u001B[0m | \u001B[0m0.8824   \u001B[0m | \u001B[0m2.178    \u001B[0m | \u001B[0m0.4446   \u001B[0m | \u001B[0m5.453    \u001B[0m | \u001B[0m0.8738   \u001B[0m | \u001B[0m475.9    \u001B[0m | \u001B[0m0.8608   \u001B[0m |\n",
      "| \u001B[0m77       \u001B[0m | \u001B[0m0.8171   \u001B[0m | \u001B[0m0.6781   \u001B[0m | \u001B[0m4.131    \u001B[0m | \u001B[0m0.03275  \u001B[0m | \u001B[0m3.504    \u001B[0m | \u001B[0m0.3992   \u001B[0m | \u001B[0m476.1    \u001B[0m | \u001B[0m0.9949   \u001B[0m |\n",
      "| \u001B[0m78       \u001B[0m | \u001B[0m0.8328   \u001B[0m | \u001B[0m0.6194   \u001B[0m | \u001B[0m3.094    \u001B[0m | \u001B[0m0.143    \u001B[0m | \u001B[0m8.229    \u001B[0m | \u001B[0m0.2727   \u001B[0m | \u001B[0m470.5    \u001B[0m | \u001B[0m0.5352   \u001B[0m |\n",
      "| \u001B[0m79       \u001B[0m | \u001B[0m0.8205   \u001B[0m | \u001B[0m0.7313   \u001B[0m | \u001B[0m0.1699   \u001B[0m | \u001B[0m0.3313   \u001B[0m | \u001B[0m9.606    \u001B[0m | \u001B[0m1.146    \u001B[0m | \u001B[0m471.0    \u001B[0m | \u001B[0m0.8567   \u001B[0m |\n",
      "| \u001B[0m80       \u001B[0m | \u001B[0m0.8249   \u001B[0m | \u001B[0m0.5263   \u001B[0m | \u001B[0m2.298    \u001B[0m | \u001B[0m0.2851   \u001B[0m | \u001B[0m3.199    \u001B[0m | \u001B[0m0.7319   \u001B[0m | \u001B[0m477.4    \u001B[0m | \u001B[0m0.6655   \u001B[0m |\n",
      "| \u001B[0m81       \u001B[0m | \u001B[0m0.8339   \u001B[0m | \u001B[0m0.8684   \u001B[0m | \u001B[0m2.55     \u001B[0m | \u001B[0m0.2407   \u001B[0m | \u001B[0m9.387    \u001B[0m | \u001B[0m1.261    \u001B[0m | \u001B[0m470.4    \u001B[0m | \u001B[0m0.5523   \u001B[0m |\n",
      "| \u001B[0m82       \u001B[0m | \u001B[0m0.8372   \u001B[0m | \u001B[0m0.6364   \u001B[0m | \u001B[0m2.067    \u001B[0m | \u001B[0m0.3752   \u001B[0m | \u001B[0m8.902    \u001B[0m | \u001B[0m0.9793   \u001B[0m | \u001B[0m472.9    \u001B[0m | \u001B[0m0.5997   \u001B[0m |\n",
      "| \u001B[0m83       \u001B[0m | \u001B[0m0.8384   \u001B[0m | \u001B[0m0.6898   \u001B[0m | \u001B[0m1.285    \u001B[0m | \u001B[0m0.2513   \u001B[0m | \u001B[0m7.848    \u001B[0m | \u001B[0m0.128    \u001B[0m | \u001B[0m500.7    \u001B[0m | \u001B[0m0.9816   \u001B[0m |\n",
      "| \u001B[0m84       \u001B[0m | \u001B[0m0.826    \u001B[0m | \u001B[0m0.7532   \u001B[0m | \u001B[0m2.497    \u001B[0m | \u001B[0m0.241    \u001B[0m | \u001B[0m6.031    \u001B[0m | \u001B[0m2.884    \u001B[0m | \u001B[0m481.2    \u001B[0m | \u001B[0m0.572    \u001B[0m |\n",
      "| \u001B[0m85       \u001B[0m | \u001B[0m0.8283   \u001B[0m | \u001B[0m0.9202   \u001B[0m | \u001B[0m4.954    \u001B[0m | \u001B[0m0.1154   \u001B[0m | \u001B[0m8.967    \u001B[0m | \u001B[0m0.3181   \u001B[0m | \u001B[0m469.5    \u001B[0m | \u001B[0m0.6732   \u001B[0m |\n",
      "| \u001B[0m86       \u001B[0m | \u001B[0m0.8182   \u001B[0m | \u001B[0m0.8376   \u001B[0m | \u001B[0m0.7506   \u001B[0m | \u001B[0m0.4329   \u001B[0m | \u001B[0m6.927    \u001B[0m | \u001B[0m0.1372   \u001B[0m | \u001B[0m497.9    \u001B[0m | \u001B[0m0.5288   \u001B[0m |\n",
      "| \u001B[0m87       \u001B[0m | \u001B[0m0.835    \u001B[0m | \u001B[0m0.784    \u001B[0m | \u001B[0m1.587    \u001B[0m | \u001B[0m0.2595   \u001B[0m | \u001B[0m8.696    \u001B[0m | \u001B[0m0.1482   \u001B[0m | \u001B[0m499.2    \u001B[0m | \u001B[0m0.9164   \u001B[0m |\n",
      "| \u001B[0m88       \u001B[0m | \u001B[0m0.8272   \u001B[0m | \u001B[0m0.962    \u001B[0m | \u001B[0m1.351    \u001B[0m | \u001B[0m0.3352   \u001B[0m | \u001B[0m8.138    \u001B[0m | \u001B[0m1.177    \u001B[0m | \u001B[0m499.6    \u001B[0m | \u001B[0m0.8509   \u001B[0m |\n",
      "| \u001B[0m89       \u001B[0m | \u001B[0m0.8317   \u001B[0m | \u001B[0m0.6766   \u001B[0m | \u001B[0m4.463    \u001B[0m | \u001B[0m0.2005   \u001B[0m | \u001B[0m8.303    \u001B[0m | \u001B[0m1.858    \u001B[0m | \u001B[0m618.6    \u001B[0m | \u001B[0m0.7291   \u001B[0m |\n",
      "| \u001B[0m90       \u001B[0m | \u001B[0m0.8227   \u001B[0m | \u001B[0m0.5479   \u001B[0m | \u001B[0m0.2564   \u001B[0m | \u001B[0m0.4889   \u001B[0m | \u001B[0m5.164    \u001B[0m | \u001B[0m9.242    \u001B[0m | \u001B[0m154.7    \u001B[0m | \u001B[0m0.8786   \u001B[0m |\n",
      "| \u001B[0m91       \u001B[0m | \u001B[0m0.8272   \u001B[0m | \u001B[0m0.5404   \u001B[0m | \u001B[0m0.1505   \u001B[0m | \u001B[0m0.2729   \u001B[0m | \u001B[0m8.427    \u001B[0m | \u001B[0m3.466    \u001B[0m | \u001B[0m274.5    \u001B[0m | \u001B[0m0.9934   \u001B[0m |\n",
      "| \u001B[0m92       \u001B[0m | \u001B[0m0.8339   \u001B[0m | \u001B[0m0.5775   \u001B[0m | \u001B[0m2.043    \u001B[0m | \u001B[0m0.2117   \u001B[0m | \u001B[0m6.968    \u001B[0m | \u001B[0m0.7297   \u001B[0m | \u001B[0m500.9    \u001B[0m | \u001B[0m0.6151   \u001B[0m |\n",
      "| \u001B[0m93       \u001B[0m | \u001B[0m0.8373   \u001B[0m | \u001B[0m0.6951   \u001B[0m | \u001B[0m1.211    \u001B[0m | \u001B[0m0.2108   \u001B[0m | \u001B[0m7.607    \u001B[0m | \u001B[0m0.7831   \u001B[0m | \u001B[0m316.0    \u001B[0m | \u001B[0m0.913    \u001B[0m |\n",
      "| \u001B[0m94       \u001B[0m | \u001B[0m0.8261   \u001B[0m | \u001B[0m0.7352   \u001B[0m | \u001B[0m4.36     \u001B[0m | \u001B[0m0.3405   \u001B[0m | \u001B[0m3.157    \u001B[0m | \u001B[0m2.333    \u001B[0m | \u001B[0m764.5    \u001B[0m | \u001B[0m0.5638   \u001B[0m |\n",
      "| \u001B[0m95       \u001B[0m | \u001B[0m0.8294   \u001B[0m | \u001B[0m0.588    \u001B[0m | \u001B[0m2.677    \u001B[0m | \u001B[0m0.1563   \u001B[0m | \u001B[0m5.779    \u001B[0m | \u001B[0m7.794    \u001B[0m | \u001B[0m626.7    \u001B[0m | \u001B[0m0.9678   \u001B[0m |\n",
      "| \u001B[0m96       \u001B[0m | \u001B[0m0.825    \u001B[0m | \u001B[0m0.6748   \u001B[0m | \u001B[0m1.66     \u001B[0m | \u001B[0m0.274    \u001B[0m | \u001B[0m7.911    \u001B[0m | \u001B[0m4.702    \u001B[0m | \u001B[0m455.8    \u001B[0m | \u001B[0m0.6654   \u001B[0m |\n",
      "| \u001B[0m97       \u001B[0m | \u001B[0m0.8227   \u001B[0m | \u001B[0m0.9138   \u001B[0m | \u001B[0m0.27     \u001B[0m | \u001B[0m0.05426  \u001B[0m | \u001B[0m5.266    \u001B[0m | \u001B[0m3.967    \u001B[0m | \u001B[0m881.0    \u001B[0m | \u001B[0m0.6343   \u001B[0m |\n",
      "| \u001B[0m98       \u001B[0m | \u001B[0m0.8193   \u001B[0m | \u001B[0m0.6713   \u001B[0m | \u001B[0m4.237    \u001B[0m | \u001B[0m0.4944   \u001B[0m | \u001B[0m8.17     \u001B[0m | \u001B[0m4.407    \u001B[0m | \u001B[0m483.8    \u001B[0m | \u001B[0m0.5771   \u001B[0m |\n",
      "| \u001B[0m99       \u001B[0m | \u001B[0m0.8294   \u001B[0m | \u001B[0m0.885    \u001B[0m | \u001B[0m1.103    \u001B[0m | \u001B[0m0.4644   \u001B[0m | \u001B[0m6.925    \u001B[0m | \u001B[0m1.457    \u001B[0m | \u001B[0m315.6    \u001B[0m | \u001B[0m0.7188   \u001B[0m |\n",
      "| \u001B[0m100      \u001B[0m | \u001B[0m0.8182   \u001B[0m | \u001B[0m0.727    \u001B[0m | \u001B[0m0.9799   \u001B[0m | \u001B[0m0.1787   \u001B[0m | \u001B[0m9.322    \u001B[0m | \u001B[0m8.568    \u001B[0m | \u001B[0m440.3    \u001B[0m | \u001B[0m0.7249   \u001B[0m |\n",
      "| \u001B[0m101      \u001B[0m | \u001B[0m0.8373   \u001B[0m | \u001B[0m0.8908   \u001B[0m | \u001B[0m3.257    \u001B[0m | \u001B[0m0.393    \u001B[0m | \u001B[0m4.742    \u001B[0m | \u001B[0m3.59     \u001B[0m | \u001B[0m259.9    \u001B[0m | \u001B[0m0.9326   \u001B[0m |\n",
      "| \u001B[0m102      \u001B[0m | \u001B[0m0.8294   \u001B[0m | \u001B[0m0.5644   \u001B[0m | \u001B[0m2.152    \u001B[0m | \u001B[0m0.4218   \u001B[0m | \u001B[0m9.88     \u001B[0m | \u001B[0m2.314    \u001B[0m | \u001B[0m471.0    \u001B[0m | \u001B[0m0.9005   \u001B[0m |\n",
      "| \u001B[0m103      \u001B[0m | \u001B[0m0.8372   \u001B[0m | \u001B[0m0.6437   \u001B[0m | \u001B[0m1.864    \u001B[0m | \u001B[0m0.03834  \u001B[0m | \u001B[0m8.694    \u001B[0m | \u001B[0m1.003    \u001B[0m | \u001B[0m470.9    \u001B[0m | \u001B[0m0.8152   \u001B[0m |\n",
      "| \u001B[0m104      \u001B[0m | \u001B[0m0.8317   \u001B[0m | \u001B[0m0.5599   \u001B[0m | \u001B[0m1.437    \u001B[0m | \u001B[0m0.05785  \u001B[0m | \u001B[0m5.314    \u001B[0m | \u001B[0m0.3355   \u001B[0m | \u001B[0m724.7    \u001B[0m | \u001B[0m0.6588   \u001B[0m |\n",
      "| \u001B[0m105      \u001B[0m | \u001B[0m0.8294   \u001B[0m | \u001B[0m0.9919   \u001B[0m | \u001B[0m3.343    \u001B[0m | \u001B[0m0.1683   \u001B[0m | \u001B[0m8.853    \u001B[0m | \u001B[0m2.199    \u001B[0m | \u001B[0m470.8    \u001B[0m | \u001B[0m0.8959   \u001B[0m |\n",
      "| \u001B[0m106      \u001B[0m | \u001B[0m0.807    \u001B[0m | \u001B[0m0.8946   \u001B[0m | \u001B[0m0.3274   \u001B[0m | \u001B[0m0.4895   \u001B[0m | \u001B[0m7.327    \u001B[0m | \u001B[0m0.07259  \u001B[0m | \u001B[0m500.8    \u001B[0m | \u001B[0m0.6614   \u001B[0m |\n",
      "| \u001B[0m107      \u001B[0m | \u001B[0m0.8205   \u001B[0m | \u001B[0m0.9434   \u001B[0m | \u001B[0m0.4577   \u001B[0m | \u001B[0m0.4496   \u001B[0m | \u001B[0m6.539    \u001B[0m | \u001B[0m8.54     \u001B[0m | \u001B[0m261.1    \u001B[0m | \u001B[0m0.8609   \u001B[0m |\n",
      "| \u001B[0m108      \u001B[0m | \u001B[0m0.8339   \u001B[0m | \u001B[0m0.6505   \u001B[0m | \u001B[0m1.682    \u001B[0m | \u001B[0m0.1768   \u001B[0m | \u001B[0m7.587    \u001B[0m | \u001B[0m0.9738   \u001B[0m | \u001B[0m500.6    \u001B[0m | \u001B[0m0.8142   \u001B[0m |\n",
      "| \u001B[0m109      \u001B[0m | \u001B[0m0.8216   \u001B[0m | \u001B[0m0.7155   \u001B[0m | \u001B[0m3.743    \u001B[0m | \u001B[0m0.454    \u001B[0m | \u001B[0m5.863    \u001B[0m | \u001B[0m0.8809   \u001B[0m | \u001B[0m143.9    \u001B[0m | \u001B[0m0.5659   \u001B[0m |\n",
      "| \u001B[0m110      \u001B[0m | \u001B[0m0.8294   \u001B[0m | \u001B[0m0.5457   \u001B[0m | \u001B[0m1.572    \u001B[0m | \u001B[0m0.4047   \u001B[0m | \u001B[0m8.23     \u001B[0m | \u001B[0m0.4735   \u001B[0m | \u001B[0m501.0    \u001B[0m | \u001B[0m0.6857   \u001B[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "pbounds = {\n",
    "    'learning_rate': (0.01, 0.5),\n",
    "    'n_estimators': (100, 1000),\n",
    "    'max_depth': (3, 10),\n",
    "    'min_child_weight': (0, 10),\n",
    "    'subsample': (0.5, 1.0),\n",
    "    'colsample_bytree': (0.5, 1.0),\n",
    "    'gamma': (0, 5)\n",
    "    # 'reg_lambda': (0, 1000, 'log-uniform'),\n",
    "    # 'reg_alpha': (0, 1.0, 'log-uniform')\n",
    "}\n",
    "\n",
    "def xgboost_hyper_param(learning_rate, n_estimators, max_depth, min_child_weight, subsample, colsample_bytree, gamma):\n",
    "    max_depth = int(max_depth)\n",
    "    n_estimators = int(n_estimators)\n",
    "    clf = XGBClassifier(\n",
    "        max_depth=max_depth,\n",
    "        min_child_weight= min_child_weight,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        gamma=gamma,\n",
    "        random_state=1,\n",
    "        eval_metric='logloss'\n",
    "        # reg_alpha=reg_alpha,\n",
    "        # reg_lambda=reg_lambda\n",
    "    )\n",
    "    return np.mean(cross_val_score(clf, train_importance, train_answer, cv=5, scoring='accuracy'))\n",
    "\n",
    "optimizer = BayesianOptimization( f=xgboost_hyper_param, pbounds=pbounds, random_state=1)\n",
    "# init_points: 초기 랜덤 포인트 갯수\n",
    "# acq='ei': Expected Improvement\n",
    "# xi=0.01: exploration(불확실성이 가장 높은 점 근처에 최적값이 존재할 것이라는 가정으로 계산된 값) 강도 (보통 0.01)\n",
    "optimizer.maximize(init_points=10, n_iter=100, acq='ei', xi=0.01)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bayesian Optimization LightGBM 적용"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001B[95m2        \u001B[0m | \u001B[95m0.8227   \u001B[0m | \u001B[95m0.5931   \u001B[0m | \u001B[95m0.1793   \u001B[0m | \u001B[95m5.777    \u001B[0m | \u001B[95m5.388    \u001B[0m | \u001B[95m477.3    \u001B[0m | \u001B[95m0.8426   \u001B[0m |\n",
      "| \u001B[95m4        \u001B[0m | \u001B[95m0.8249   \u001B[0m | \u001B[95m0.5702   \u001B[0m | \u001B[95m0.1071   \u001B[0m | \u001B[95m8.605    \u001B[0m | \u001B[95m9.683    \u001B[0m | \u001B[95m382.1    \u001B[0m | \u001B[95m0.8462   \u001B[0m |\n",
      "| \u001B[95m9        \u001B[0m | \u001B[95m0.8339   \u001B[0m | \u001B[95m0.6439   \u001B[0m | \u001B[95m0.07371  \u001B[0m | \u001B[95m3.136    \u001B[0m | \u001B[95m6.788    \u001B[0m | \u001B[95m290.5    \u001B[0m | \u001B[95m0.6328   \u001B[0m |\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pbounds = {\n",
    "    'learning_rate': (0.01, 0.5),\n",
    "    'n_estimators': (100, 1000),\n",
    "    'max_depth': (3, 10),\n",
    "    'min_child_weight': (0, 10),\n",
    "    'subsample': (0.5, 1.0),\n",
    "    'colsample_bytree': (0.5, 1.0)\n",
    "    # 'reg_lambda': (0, 1000),\n",
    "    # 'reg_alpha': (0, 1.0)\n",
    "}\n",
    "\n",
    "def lgbm_hyper_param(learning_rate, n_estimators, max_depth, min_child_weight, subsample, colsample_bytree):\n",
    "    max_depth = int(max_depth)\n",
    "    n_estimators = int(n_estimators)\n",
    "    clf = LGBMClassifier(\n",
    "        max_depth=max_depth,\n",
    "        min_child_weight=min_child_weight,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        random_state=1\n",
    "        # reg_lambda=reg_lambda,\n",
    "        # reg_alpha=reg_alpha\n",
    "    )\n",
    "    return np.mean(cross_val_score(clf, train_importance, train_answer, cv=5, scoring='accuracy'))   # cv 도 숫자로 작성하여, 내부적으로 (Stratified)KFold 사용함\n",
    "\n",
    "optimizer = BayesianOptimization( f=lgbm_hyper_param, pbounds=pbounds, verbose=1, random_state=1)\n",
    "optimizer.maximize(init_points=10, n_iter=100, acq='ei', xi=0.01)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 9. Grid Search XGBoost 적용"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Grid Search XGBoost 적용 1단계\n",
    "- 주요 파라미터를 모두 넣을 경우, 수행시간이 매우 길어지므로, 3단계로 나누어서 테스트"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "0.8439897056054233\n",
      "{'learning_rate': 0.005, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "learning_rate = [0.001, 0.005, 0.01, 0.05, 0.06, 0.1, 0.12, 0.15, 0.17, 0.2]\n",
    "n_estimators = [10, 50, 60, 75, 85, 100, 125, 150, 200, 250, 500, 1000]\n",
    "\n",
    "hyperparams = {\n",
    "    'learning_rate': learning_rate,\n",
    "    'n_estimators': n_estimators\n",
    "}\n",
    "\n",
    "gd=GridSearchCV(\n",
    "    estimator = XGBClassifier(random_state=1, eval_metric='logloss'),\n",
    "    param_grid = hyperparams,\n",
    "    verbose=True,\n",
    "    cv=5,\n",
    "    scoring = \"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gd.fit(train_importance, train_answer)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Grid Search XGBoost 적용 2단계"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "0.8439897056054233\n",
      "{'max_depth': 6, 'min_child_weight': 1}\n"
     ]
    }
   ],
   "source": [
    "max_depth = [3, 4, 5, 6, 7, 8, 9, 10]\n",
    "min_child_weight = [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "hyperparams = {\n",
    "    'max_depth': max_depth,\n",
    "    'min_child_weight': min_child_weight\n",
    "}\n",
    "\n",
    "gd=GridSearchCV(\n",
    "    estimator = XGBClassifier(learning_rate=0.17, n_estimators=10, random_state=1, eval_metric='logloss'),\n",
    "    param_grid = hyperparams,\n",
    "    verbose=True,\n",
    "    cv=5,\n",
    "    scoring = \"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gd.fit(train_importance, train_answer)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Grid Search XGBoost 적용 3단계"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2025 candidates, totalling 10125 fits\n",
      "0.8462306195467957\n",
      "{'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 0.1, 'subsample': 0.85}\n"
     ]
    }
   ],
   "source": [
    "gamma =  [i*0.1 for i in range(0,5)]\n",
    "subsample = [0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "colsample_bytree = [0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "reg_alpha = [1e-5, 1e-2, 0.1, 1, 100]\n",
    "\n",
    "hyperparams = {\n",
    "    'gamma': gamma,\n",
    "    'subsample':subsample,\n",
    "    'colsample_bytree':colsample_bytree,\n",
    "    'reg_alpha': reg_alpha\n",
    "}\n",
    "\n",
    "gd=GridSearchCV(\n",
    "    estimator = XGBClassifier(\n",
    "        learning_rate=0.17,\n",
    "        n_estimators=10,\n",
    "        max_depth=6,\n",
    "        min_child_weight=1,\n",
    "        random_state=1,\n",
    "        eval_metric='logloss'\n",
    "    ),\n",
    "    param_grid = hyperparams,\n",
    "    verbose=True,\n",
    "    cv=5,\n",
    "    scoring = \"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gd.fit(train_importance, train_answer)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "0.8283095850856819\n",
      "{'n_neighbors': 6}\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "hyperparams = {\n",
    "    'n_neighbors': n_neighbors\n",
    "}\n",
    "\n",
    "gd=GridSearchCV(\n",
    "    estimator = KNeighborsClassifier(),\n",
    "    param_grid = hyperparams,\n",
    "    verbose=True,\n",
    "    cv=5,\n",
    "    scoring = \"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gd.fit(train_importance, train_answer)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1200 candidates, totalling 6000 fits\n",
      "0.8484715334881676\n",
      "{'max_depth': None, 'max_features': 0.8, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [10, 50, 100, 200]\n",
    "max_depth = [3, None]\n",
    "max_features = [0.1, 0.2, 0.5, 0.8, 'sqrt', 'log2'] # feature 수\n",
    "min_samples_split = [2, 4, 6, 8, 10] # 노드를 분할하기 위한 최소 샘플 수\n",
    "min_samples_leaf = [2, 4, 6, 8, 10] # 리프 노드가 되기 위해 필요한 최소 샘플 수\n",
    "\n",
    "hyperparams = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth': max_depth,\n",
    "    'max_features': max_features,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf\n",
    "}\n",
    "\n",
    "gd=GridSearchCV(\n",
    "    estimator = RandomForestClassifier(random_state=1),\n",
    "    param_grid = hyperparams,\n",
    "    verbose=True,\n",
    "    cv=5,\n",
    "    scoring = \"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gd.fit(train_importance, train_answer)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extra Trees"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1200 candidates, totalling 6000 fits\n",
      "0.8529721925805035\n",
      "{'max_depth': None, 'max_features': 0.2, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [10, 50, 100, 200]\n",
    "max_depth = [3, None]\n",
    "max_features = [0.1, 0.2, 0.5, 0.8, 'sqrt', 'log2'] # feature 수\n",
    "min_samples_split = [2, 4, 6, 8, 10] # 노드를 분할하기 위한 최소 샘플 수\n",
    "min_samples_leaf = [2, 4, 6, 8, 10] # 리프 노드가 되기 위해 필요한 최소 샘플 수\n",
    "\n",
    "hyperparams = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth': max_depth,\n",
    "    'max_features': max_features,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf\n",
    "}\n",
    "\n",
    "gd=GridSearchCV(\n",
    "    estimator = ExtraTreesClassifier(random_state=1),\n",
    "    param_grid = hyperparams,\n",
    "    verbose=True,\n",
    "    cv=5,\n",
    "    scoring = \"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gd.fit(train_importance, train_answer)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
