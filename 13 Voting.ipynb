{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('titanic_step4_importance_train.pickle', 'rb') as pickle_filename:\n",
    "    train_importance = pickle.load(pickle_filename)\n",
    "with open('titanic_step4_importance_test.pickle', 'rb') as pickle_filename:\n",
    "    test_importance = pickle.load(pickle_filename)\n",
    "with open('titanic_step4_importance_train_y.pickle', 'rb') as pickle_filename:\n",
    "    train_answer = pickle.load(pickle_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 모델 재트레이닝"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# loggistic model\n",
    "logreg_model = LogisticRegression(\n",
    "    C=18.288277344191805,\n",
    "    penalty='l2',\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# xgb\n",
    "xgb_model = XGBClassifier(\n",
    "    eval_metric = 'logloss',\n",
    "    learning_rate=0.17,\n",
    "    n_estimators=10,\n",
    "    max_depth=6,\n",
    "    min_child_weight=1,\n",
    "    gamma=0.2,\n",
    "    reg_alpha=0.01,\n",
    "    colsample_bytree=0.85,\n",
    "    subsample=0.9,\n",
    "    random_state=1\n",
    ")\n",
    "# randomForest\n",
    "random_model = RandomForestClassifier(\n",
    "    max_depth=None,\n",
    "    max_features=0.8,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=6,\n",
    "    n_estimators=200,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "#extra tree\n",
    "extra_model = ExtraTreesClassifier(\n",
    "    max_depth=None,\n",
    "    max_features=0.5,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=10,\n",
    "    n_estimators=50,\n",
    "    random_state=1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Voting Classifier\n",
    "- 일종의 앙상블(ensemble) 의 또다른 기법3 으로(기법1은 Bagging, 기법2는 Boosting), 여러 모델들을 기반으로, 투표를 하는 Voting 기법이 있음\n",
    "- 해당 기법을 사용하여 성능이 괜찮은 모델을 기반으로 Voting 을 해서, 또다른 예측 모델을 구성할 수 있음\n",
    "- Voting 기법도 크게 Hard Voting 기법과 Soft Voting 기법이 존재함"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hard Voting Classifier\n",
    "- 여러 모델이 예측한 분류 중, 가장 많은 모델이 예측한 분류를 선택하는 기법\n",
    "\n",
    "<img src=\"https://www.fun-coding.org/00_Images/hardvoting.png\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.96076831335134\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "grid_hard = VotingClassifier(estimators= [\n",
    "    ('Logistic Regression', logreg_model),\n",
    "    ('XGBoost', xgb_model),\n",
    "    ('Random Forest', random_model),\n",
    "    ('Extra Trees', extra_model),\n",
    "], voting='hard')\n",
    "\n",
    "score = cross_val_score(grid_hard, train_importance, train_answer, cv=5, scoring='accuracy')\n",
    "print(np.mean(score)*100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Soft Voting Classifier\n",
    "- 여러 모델을 확률로 예측 분류한 후, 예측 확률의 평균을 내어, 확률이 가장 높은 분류를 선택하는 기법\n",
    "\n",
    "<img src=\"https://www.fun-coding.org/00_Images/softvoting.png\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.28661100998053\n"
     ]
    }
   ],
   "source": [
    "# 튜닝한 파라미터로 소프트보팅\n",
    "grid_soft = VotingClassifier(estimators = [\n",
    "    ('Logistic Regression', logreg_model),\n",
    "    ('XGBoost', xgb_model),\n",
    "    ('Random Forest', random_model),\n",
    "    ('Extra Trees', extra_model),\n",
    "], voting = 'soft')\n",
    "\n",
    "score = cross_val_score(grid_soft, train_importance, train_answer, cv=5, scoring='accuracy')\n",
    "print(np.mean(score)*100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "   PassengerId Survived\n0          892      NaN\n1          893      NaN\n2          894      NaN\n3          895      NaN\n4          896      NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../Study_For_MachineLearning/test.csv')\n",
    "submission = pd.DataFrame(columns=['PassengerId', 'Survived'])\n",
    "submission['PassengerId'] = test['PassengerId']\n",
    "submission.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "VotingClassifier(estimators=[('Logistic Regression',\n                              LogisticRegression(C=18.288277344191805,\n                                                 random_state=1)),\n                             ('XGBoost',\n                              XGBClassifier(base_score=None, booster=None,\n                                            callbacks=None,\n                                            colsample_bylevel=None,\n                                            colsample_bynode=None,\n                                            colsample_bytree=0.85,\n                                            early_stopping_rounds=None,\n                                            enable_categorical=False,\n                                            eval_metric='logloss',\n                                            feature_types=None, gamma=0.2,\n                                            gpu...\n                                            monotone_constraints=None,\n                                            n_estimators=10, n_jobs=None,\n                                            num_parallel_tree=None,\n                                            predictor=None, random_state=1, ...)),\n                             ('Random Forest',\n                              RandomForestClassifier(max_features=0.8,\n                                                     min_samples_leaf=2,\n                                                     min_samples_split=6,\n                                                     n_estimators=200,\n                                                     random_state=1)),\n                             ('Extra Trees',\n                              ExtraTreesClassifier(max_features=0.5,\n                                                   min_samples_leaf=2,\n                                                   min_samples_split=10,\n                                                   n_estimators=50,\n                                                   random_state=1))])",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;Logistic Regression&#x27;,\n                              LogisticRegression(C=18.288277344191805,\n                                                 random_state=1)),\n                             (&#x27;XGBoost&#x27;,\n                              XGBClassifier(base_score=None, booster=None,\n                                            callbacks=None,\n                                            colsample_bylevel=None,\n                                            colsample_bynode=None,\n                                            colsample_bytree=0.85,\n                                            early_stopping_rounds=None,\n                                            enable_categorical=False,\n                                            eval_metric=&#x27;logloss&#x27;,\n                                            feature_types=None, gamma=0.2,\n                                            gpu...\n                                            monotone_constraints=None,\n                                            n_estimators=10, n_jobs=None,\n                                            num_parallel_tree=None,\n                                            predictor=None, random_state=1, ...)),\n                             (&#x27;Random Forest&#x27;,\n                              RandomForestClassifier(max_features=0.8,\n                                                     min_samples_leaf=2,\n                                                     min_samples_split=6,\n                                                     n_estimators=200,\n                                                     random_state=1)),\n                             (&#x27;Extra Trees&#x27;,\n                              ExtraTreesClassifier(max_features=0.5,\n                                                   min_samples_leaf=2,\n                                                   min_samples_split=10,\n                                                   n_estimators=50,\n                                                   random_state=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;Logistic Regression&#x27;,\n                              LogisticRegression(C=18.288277344191805,\n                                                 random_state=1)),\n                             (&#x27;XGBoost&#x27;,\n                              XGBClassifier(base_score=None, booster=None,\n                                            callbacks=None,\n                                            colsample_bylevel=None,\n                                            colsample_bynode=None,\n                                            colsample_bytree=0.85,\n                                            early_stopping_rounds=None,\n                                            enable_categorical=False,\n                                            eval_metric=&#x27;logloss&#x27;,\n                                            feature_types=None, gamma=0.2,\n                                            gpu...\n                                            monotone_constraints=None,\n                                            n_estimators=10, n_jobs=None,\n                                            num_parallel_tree=None,\n                                            predictor=None, random_state=1, ...)),\n                             (&#x27;Random Forest&#x27;,\n                              RandomForestClassifier(max_features=0.8,\n                                                     min_samples_leaf=2,\n                                                     min_samples_split=6,\n                                                     n_estimators=200,\n                                                     random_state=1)),\n                             (&#x27;Extra Trees&#x27;,\n                              ExtraTreesClassifier(max_features=0.5,\n                                                   min_samples_leaf=2,\n                                                   min_samples_split=10,\n                                                   n_estimators=50,\n                                                   random_state=1))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Logistic Regression</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=18.288277344191805, random_state=1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>XGBoost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.85, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n              feature_types=None, gamma=0.2, gpu_id=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.17, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n              max_leaves=None, min_child_weight=1, missing=nan,\n              monotone_constraints=None, n_estimators=10, n_jobs=None,\n              num_parallel_tree=None, predictor=None, random_state=1, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Random Forest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=0.8, min_samples_leaf=2,\n                       min_samples_split=6, n_estimators=200, random_state=1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Extra Trees</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(max_features=0.5, min_samples_leaf=2, min_samples_split=10,\n                     n_estimators=50, random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_hard.fit(train_importance, train_answer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "   PassengerId  Survived\n0          892         0\n1          893         0\n2          894         0\n3          895         0\n4          896         1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[\"Survived\"] = grid_hard.predict(test_importance)\n",
    "submission = submission.astype(\"int\")\n",
    "submission.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "submission.to_csv('titanic_predict.csv', header=True, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Titanic - Machine Learning from Disaster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/3.18k [00:00<?, ?B/s]\n",
      "100%|##########| 3.18k/3.18k [00:00<00:00, 29.1kB/s]\n",
      "100%|##########| 3.18k/3.18k [00:03<00:00, 878B/s]  \n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c titanic -f titanic_predict.csv -m \"Test\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
