{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Cross Validation (교차 검증에 대한 이해)\n",
    "- 학습데이터(train)으로 학습을 한 뒤, 테스트 데이터(test)에 대해 학습된 모델을 통해 예측값을 도출\n",
    "    - 이때, 학습된 데이터로 **학습된 모델을 평가하고, 개선하기 위해 검증데이터**가 필요하다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Holdout Cross Validation ( 잘 안 쓰인다.)\n",
    "- 학습데이터와 검증데이터를 고정된 길이로 분리하는 것\n",
    "    - ex) 8:2, 7:3, 9:1\n",
    "- 고정적인 검증 데이터로 모델을 평가/개선할 경우, 검증데이터에만 overfit이 될 수 있음.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. K-fold Cross Validation\n",
    "- 데이터를 k개로 분할 (각 분할된 서브 데이터를 fold라고 부른다.)\n",
    "1. 각 fold를 선택해서, 해당 fold 이외의 **k-1**개의 나머지 fold로 훈련(학습)을 시킨 후에  **특정 fold로 테스트(test)** 를 해서 검증 점수를 도출한다.\n",
    "2. 즉, 위의 방식으로 k번 반복 하므로, **k개의 검증 점수가 계산됨**, 이들의 **평균**을 계산해서 **최종 검증 점수**를 계산한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sklearn과 Cross Validation & K-fold\n",
    "```python\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sklearn의 Cross Validation & K-fold 사용법\n",
    "- KFold\n",
    "    - n_splits: 나누는 갯수\n",
    "    - shuffle(default: False): 각 그룹의 데이터를 섞는지에 대한 여부\n",
    "    - random_state(랜덤값을 고정): shuffle이 True일 때, 랜덤하게 데이터를 섞는데, 이 때, random_state값을 정수값으로 설정하면, 여러 번 실행해도 동일한 랜덤값으로 동일하게 각 그룹에 데이터를 섞는다. (컴퓨터의 랜덤함수는 보통 현재 시각을 기반으로 랜덤값을 결정한다.)\n",
    "\n",
    "- cross_val_score(estimator, x, y, cv, n_jobs, scoring)\n",
    "    - estimator: 모델 객체를 넣어주면 된다. (학습할 모델을 의미한다.)\n",
    "    - x: train할 데이터(feature 값)\n",
    "    - y: train할 데이터의 실제 값\n",
    "    - cv: 정수 또는 KFold와 같은 객체명\n",
    "    - n_jobs: -1이면 모든 CPU 코어를 사용해서 병렬 수행, 병렬 수행할 CPU의 갯수\n",
    "    - scoring: 모델 평가 계산식을 사용 (보통 'accuracy' 사용)\n",
    "- cross_val_score()의 리턴값 -> scoring계산식을 통해, 게산된 각 그룹에 대한 모델 평가값을 **배열**로 반환\n",
    "\n",
    "```python\n",
    "# K-Fold 사용 예제\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "score = cross_val_score(estimator=knn, x=train, y=train, cv=k_fold, n_jobs=-1, scoring='accuracy')\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
