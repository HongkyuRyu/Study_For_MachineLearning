{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import string\n",
    "import warnings\n",
    "import missingno\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../Study_For_MachineLearning/Bike/train.csv')\n",
    "df_test = pd.read_csv('../Study_For_MachineLearning/Bike/test.csv')\n",
    "df_all = pd.concat((df_train, df_test)).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10886, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def split_df(df):\n",
    "    return df[:10886], df[10886:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RMSLE 기반 예측을 위해서 Log필드를 추가한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df_all['casual_log'] = np.log(df_all['casual'] + 1)\n",
    "df_all['registered_log'] = np.log(df_all['registered'] + 1)\n",
    "df_all['count_log'] = np.log(df_all['count']+1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 시간필드 추가"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dt = pd.DatetimeIndex(df_all['datetime'])\n",
    "df_all.set_index(dt, inplace=True)\n",
    "\n",
    "df_all['date'] = dt.date\n",
    "df_all['day'] = dt.day\n",
    "df_all['month'] = dt.month\n",
    "df_all['year'] = dt.year\n",
    "df_all['hour'] = dt.hour\n",
    "df_all['dow'] = dt.dayofweek\n",
    "df_all['woy'] = dt.weekofyear"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 바쁜 시간대 타임 필드 추가"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def func(df_data):\n",
    "    if df_data['workingday'] == 1:\n",
    "        if (df_data['hour'] == 8) or (df_data['hour'] == 17) or (df_data['hour'] == 18):\n",
    "            return 4\n",
    "        elif (df_data['hour'] == 7) or (df_data['hour'] == 16) or (df_data['hour'] == 19):\n",
    "            return 3\n",
    "    else:\n",
    "        if (df_data['hour'] >= 12 and df_data['hour'] <= 16):\n",
    "            return 2\n",
    "        elif (df_data['hour'] >= 10 and df_data['hour'] <= 19):\n",
    "            return 1\n",
    "    return 0\n",
    "df_all['peak'] = df_all.apply(func, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### holiday 필드 추가"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def func(df_data):\n",
    "    if (df_data['month'] == 12) and (df_data['day'] == 24 or df_data['day'] == 31):\n",
    "        return 1\n",
    "    return df_data['holiday']\n",
    "df_all['holiday'] = df_all.apply(func, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### workingday 필드 추가"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def func(df_data):\n",
    "    if (df_data['month'] == 12) and (df_data['day'] == 24 or df_data['day'] == 31):\n",
    "        return 0\n",
    "    return df_data['workingday']\n",
    "df_all['workingday'] = df_all.apply(func, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 온도, 풍속, 습도, 날씨 기반 fit & humid 필드 추가"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def func(df_data):\n",
    "    if (df_data['weather'] <= 2 and df_data['windspeed'] <= 20):\n",
    "        if (df_data['temp'] > 15 and df_data['temp'] <= 35):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "df_all['fit'] = df_all.apply(func, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def func(df_data):\n",
    "    if df_data['humidity'] >= 70:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df_all['humid'] = df_all.apply(func, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$ RMSLE = \\sqrt{\\dfrac{\\sum_{i=0}^N (log(y_i + 1) - log(\\hat{y_i} + 1))^2 }{N}} $$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def get_rmsle(y_actual, y_pred):\n",
    "    diff = np.log(y_pred + 1) - np.log(y_actual + 1)\n",
    "    mean_error = np.square(diff).mean()\n",
    "    return np.sqrt(mean_error)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def predict_bikecount(model, select_columns):\n",
    "    df_train, df_test = split_df(df_all)\n",
    "\n",
    "    X_train = df_train[select_columns]\n",
    "    y_train_cas = df_train['casual_log']\n",
    "    y_train_reg = df_train['registered_log']\n",
    "    X_test = df_test[select_columns]\n",
    "\n",
    "    casual_model = model.fit(X_train, y_train_cas)\n",
    "    y_pred_cas = casual_model.predict(X_test)\n",
    "    y_pred_cas = np.exp(y_pred_cas) - 1\n",
    "\n",
    "    registered_model = model.fit(X_train, y_train_reg)\n",
    "    y_pred_reg = registered_model.predict(X_test)\n",
    "    y_pred_reg = np.exp(y_pred_reg) - 1\n",
    "\n",
    "    return y_pred_cas + y_pred_reg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LinearRegression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "df_train, df_test = split_df(df_all)\n",
    "ml_columns = [\n",
    "    'season', 'holiday', 'workingday', 'weather', 'temp',\n",
    "    'atemp', 'humidity', 'windspeed', 'day', 'month',\n",
    "    'year', 'hour', 'dow', 'woy', 'peak', 'fit', 'humid'\n",
    "]\n",
    "X_train = df_train[ml_columns].copy()\n",
    "y_train = df_train['count']\n",
    "rmsle_scorer = make_scorer(get_rmsle, greater_is_better=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr_model = LinearRegression()\n",
    "ml_pred = predict_bikecount(lr_model, ml_columns)\n",
    "df_test['count'] = ml_pred\n",
    "final_df = df_test[['datetime', 'count']].copy()\n",
    "final_df.to_csv('submissions_linear.csv', header=True, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Bike Sharing Demand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/250k [00:00<?, ?B/s]\n",
      "  3%|3         | 8.00k/250k [00:00<00:03, 69.7kB/s]\n",
      " 77%|#######6  | 192k/250k [00:00<00:00, 1.06MB/s] \n",
      "100%|##########| 250k/250k [00:02<00:00, 98.4kB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c bike-sharing-demand -f submissions_linear.csv -m \"Message\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lasso Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      "{'alpha': 10.0, 'max_iter': 1000}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperparams = {\n",
    "    'max_iter' : [1000, 1500, 2000, 2500, 3000],\n",
    "    'alpha': 1/np.array([0.1, 1, 2, 3, 4, 10, 30,100,200,300,400,800,900,1000])\n",
    "}\n",
    "lasso_grid = GridSearchCV(\n",
    "    estimator=Lasso(),\n",
    "    param_grid=hyperparams,\n",
    "    verbose=True,\n",
    "    scoring=rmsle_scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "print(lasso_grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Bike Sharing Demand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/246k [00:00<?, ?B/s]\n",
      "  3%|3         | 8.00k/246k [00:00<00:03, 66.5kB/s]\n",
      " 75%|#######4  | 184k/246k [00:00<00:00, 970kB/s]  \n",
      "100%|##########| 246k/246k [00:03<00:00, 82.7kB/s]\n"
     ]
    }
   ],
   "source": [
    "lasso_model = lasso_grid.best_estimator_\n",
    "ml_pred = predict_bikecount(lasso_model, ml_columns)\n",
    "df_test['count'] = ml_pred\n",
    "final_df = df_test[['datetime', 'count']].copy()\n",
    "final_df.to_csv('submissions_lasso.csv', header=True, index=False)\n",
    "!kaggle competitions submit -c bike-sharing-demand -f submissions_lasso.csv -m \"Message\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ridge"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
      "{'alpha': 1000, 'max_iter': 1000}\n",
      "Ridge(alpha=1000, max_iter=1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperparams = {'max_iter': [1000, 1500, 2000, 2500, 3000],\n",
    "               'alpha':[0.1, 1, 2, 3, 4, 10, 30,100,200,300,400,800,900,1000]\n",
    "               }\n",
    "ridge_grid = GridSearchCV(\n",
    "    estimator=Ridge(),\n",
    "    param_grid=hyperparams,\n",
    "    verbose=True,\n",
    "    scoring=rmsle_scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "print(ridge_grid.best_params_)\n",
    "print(ridge_grid.best_estimator_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Bike Sharing Demand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/250k [00:00<?, ?B/s]\n",
      "  3%|3         | 8.00k/250k [00:00<00:03, 70.0kB/s]\n",
      "100%|##########| 250k/250k [00:02<00:00, 90.2kB/s] \n"
     ]
    }
   ],
   "source": [
    "ridge_model = ridge_grid.best_estimator_\n",
    "ml_pred = predict_bikecount(ridge_model, ml_columns)\n",
    "df_test['count'] = ml_pred\n",
    "final_df = df_test[['datetime', 'count']].copy()\n",
    "final_df.to_csv('submissions_ridge.csv', header=True, index=False)\n",
    "!kaggle competitions submit -c bike-sharing-demand -f submissions_ridge.csv -m \"Message\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest Regressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 13\u001B[0m\n\u001B[0;32m      8\u001B[0m hyperparams \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_estimators\u001B[39m\u001B[38;5;124m'\u001B[39m: n_estimators, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m'\u001B[39m: max_depth,\n\u001B[0;32m      9\u001B[0m                \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmin_samples_split\u001B[39m\u001B[38;5;124m'\u001B[39m: min_samples_split, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmin_samples_leaf\u001B[39m\u001B[38;5;124m'\u001B[39m: min_samples_leaf}\n\u001B[0;32m     10\u001B[0m rf_grid \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator \u001B[38;5;241m=\u001B[39m RandomForestRegressor(),\n\u001B[0;32m     11\u001B[0m                        param_grid \u001B[38;5;241m=\u001B[39m hyperparams,\n\u001B[0;32m     12\u001B[0m                        verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, scoring\u001B[38;5;241m=\u001B[39mrmsle_scorer, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 13\u001B[0m \u001B[43mrf_grid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(rf_grid\u001B[38;5;241m.\u001B[39mbest_params_)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    869\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    870\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    871\u001B[0m     )\n\u001B[0;32m    873\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 875\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    878\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    879\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1389\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1387\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1388\u001B[0m     \u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1389\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    815\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    816\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    817\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    818\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    819\u001B[0m         )\n\u001B[0;32m    820\u001B[0m     )\n\u001B[1;32m--> 822\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    823\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    827\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    828\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    829\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    831\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    832\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    833\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    834\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    835\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    836\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    837\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    839\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    840\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    841\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    842\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    843\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    844\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py:1061\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1058\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   1060\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1061\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1062\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[0;32m   1063\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\joblib\\parallel.py:938\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    936\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    937\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m--> 938\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    939\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    940\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[1;34m(future, timeout)\u001B[0m\n\u001B[0;32m    539\u001B[0m \u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[0;32m    540\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[0;32m    541\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 542\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    543\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    544\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\concurrent\\futures\\_base.py:453\u001B[0m, in \u001B[0;36mFuture.result\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    450\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m    451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[1;32m--> 453\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[0;32m    456\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_estimators = [800, 1000, 1200]\n",
    "max_depth = [10, 12, 15]\n",
    "min_samples_split = [4, 5, 6]\n",
    "min_samples_leaf = [4, 5, 6]\n",
    "\n",
    "hyperparams = {'n_estimators': n_estimators, 'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf}\n",
    "rf_grid = GridSearchCV(estimator = RandomForestRegressor(),\n",
    "                       param_grid = hyperparams,\n",
    "                       verbose=True, scoring=rmsle_scorer, cv=5, n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "print(rf_grid.best_params_)\n",
    "## 너무 오래 걸려서 중지시킴."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# rf_model = rf_grid.best_estimator_\n",
    "# ml_pred = predict_bikecount(rf_model, ml_columns)\n",
    "# df_test['count'] = ml_pred\n",
    "# final_df = df_test[['datetime', 'count']].copy()\n",
    "# final_df.to_csv('submissions_rf.csv', header=True, index=False)\n",
    "# !kaggle competitions submit -c bike-sharing-demand -f submissions_rf.csv -m \"Message\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### XGBOOST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "{'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 250, 'nthread': 4, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperparams = {'nthread':[4],\n",
    "               'learning_rate': [0.05, 0.1, 0.15],\n",
    "               'max_depth': [4, 5],\n",
    "               'min_child_weight': [3, 4, 5],\n",
    "               'subsample': [0.7, 0.8],\n",
    "               'colsample_bytree': [0.6, 0.7],\n",
    "               'n_estimators': [250, 500]}\n",
    "\n",
    "xgb_grid = GridSearchCV(estimator = XGBRegressor(),\n",
    "                        param_grid = hyperparams,\n",
    "                        verbose=True, scoring=rmsle_scorer, cv=5, n_jobs=-1)\n",
    "\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "print(xgb_grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Bike Sharing Demand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/194k [00:00<?, ?B/s]\n",
      "  4%|4         | 8.00k/194k [00:00<00:02, 65.5kB/s]\n",
      " 95%|#########4| 184k/194k [00:00<00:00, 981kB/s]  \n",
      "100%|##########| 194k/194k [00:02<00:00, 68.1kB/s]\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb_grid.best_estimator_\n",
    "ml_pred = predict_bikecount(xgb_model, X_train.columns)\n",
    "df_test['count'] = ml_pred\n",
    "final_df = df_test[['datetime', 'count']].copy()\n",
    "final_df.to_csv('submissions_xgboost.csv', header=True, index=False)\n",
    "!kaggle competitions submit -c bike-sharing-demand -f submissions_xgboost.csv -m \"Message\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradient Boosting Regressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "{'learning_rate': 0.1, 'max_depth': 9, 'min_samples_leaf': 8, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_estimators = [100, 150, 200]\n",
    "max_depth = [5, 7, 9]\n",
    "min_samples_leaf = [8, 10, 12]\n",
    "learning_rate = [0.1, 0.15, 0.2]\n",
    "subsample = [0.6, 0.7, 0.8]\n",
    "\n",
    "hyperparams = {'n_estimators': n_estimators, 'max_depth': max_depth,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'learning_rate': learning_rate, 'subsample': subsample\n",
    "               }\n",
    "\n",
    "gb_grid=GridSearchCV(estimator = GradientBoostingRegressor(), param_grid = hyperparams,\n",
    "                     verbose=True, scoring=rmsle_scorer, cv=5, n_jobs=-1)\n",
    "\n",
    "gb_grid.fit(X_train, y_train)\n",
    "print(gb_grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Bike Sharing Demand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/250k [00:00<?, ?B/s]\n",
      "  3%|3         | 8.00k/250k [00:00<00:03, 63.0kB/s]\n",
      " 74%|#######3  | 184k/250k [00:00<00:00, 946kB/s]  \n",
      "100%|##########| 250k/250k [00:03<00:00, 71.9kB/s]\n"
     ]
    }
   ],
   "source": [
    "gb_model = gb_grid.best_estimator_\n",
    "ml_pred = predict_bikecount(gb_model, X_train.columns)\n",
    "df_test['count'] = ml_pred\n",
    "final_df = df_test[['datetime', 'count']].copy()\n",
    "final_df.to_csv('submissions_gb.csv', header=True, index=False)\n",
    "!kaggle competitions submit -c bike-sharing-demand -f submissions_gb.csv -m \"Message\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
